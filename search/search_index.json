{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"cupid_matching \u00b6 A Python package to solve, simulate and estimate separable matching models Free software: MIT license Documentation: https://bsalanie.github.io/cupid_matching See also: An interactive Streamlit app Installation \u00b6 1 pip install -U cupid_matching Accessing the code \u00b6 For instance: 1 from cupid_matching.min_distance import estimate_semilinear_mde An example \u00b6 We create a Choo-Siow market; we solve for the stable matching in an infinite ppulation using IPFP; we simulate a sample drawn from the stable matching and we estimate the coefficients of the basis functions using both minimum distance and Poisson GLM estimators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import numpy as np from cupid_matching.model_classes import ChooSiowPrimitives from cupid_matching.choo_siow import entropy_choo_siow from cupid_matching.min_distance import estimate_semilinear_mde from cupid_matching.poisson_glm import choo_siow_poisson_glm X , Y , K = 10 , 20 , 2 # we simulate a Choo and Siow population # with 10 types of men and 20 types of women # with equal numbers of men and women of each type # and two random basis functions lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) matching_popu = choo_siow_instance . ipfp_solve () muxy_popu , mux0_popu , mu0y_popu , n_popu , m_popu \\ = matching_popu . unpack () # we simulate the market on a finite population n_households = int ( 1e6 ) mus_sim = choo_siow_instance . simulate ( n_households ) choo_siow_instance . describe () # We estimate the parameters using minimum distance mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy_choo_siow , more_params = None ) # we print and check the results mde_discrepancy = mde_results . print_results ( true_coeffs = lambda_true , n_alpha = 0 ) # we also estimate using Poisson GLM poisson_results = choo_siow_poisson_glm ( mus_sim , phi_bases ) muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim \\ = mus_sim . unpack () poisson_discrepancy = poisson_results . print_results ( lambda_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ) )","title":"Home"},{"location":"#cupid_matching","text":"A Python package to solve, simulate and estimate separable matching models Free software: MIT license Documentation: https://bsalanie.github.io/cupid_matching See also: An interactive Streamlit app","title":"cupid_matching"},{"location":"#installation","text":"1 pip install -U cupid_matching","title":"Installation"},{"location":"#accessing-the-code","text":"For instance: 1 from cupid_matching.min_distance import estimate_semilinear_mde","title":"Accessing the code"},{"location":"#an-example","text":"We create a Choo-Siow market; we solve for the stable matching in an infinite ppulation using IPFP; we simulate a sample drawn from the stable matching and we estimate the coefficients of the basis functions using both minimum distance and Poisson GLM estimators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import numpy as np from cupid_matching.model_classes import ChooSiowPrimitives from cupid_matching.choo_siow import entropy_choo_siow from cupid_matching.min_distance import estimate_semilinear_mde from cupid_matching.poisson_glm import choo_siow_poisson_glm X , Y , K = 10 , 20 , 2 # we simulate a Choo and Siow population # with 10 types of men and 20 types of women # with equal numbers of men and women of each type # and two random basis functions lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) matching_popu = choo_siow_instance . ipfp_solve () muxy_popu , mux0_popu , mu0y_popu , n_popu , m_popu \\ = matching_popu . unpack () # we simulate the market on a finite population n_households = int ( 1e6 ) mus_sim = choo_siow_instance . simulate ( n_households ) choo_siow_instance . describe () # We estimate the parameters using minimum distance mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy_choo_siow , more_params = None ) # we print and check the results mde_discrepancy = mde_results . print_results ( true_coeffs = lambda_true , n_alpha = 0 ) # we also estimate using Poisson GLM poisson_results = choo_siow_poisson_glm ( mus_sim , phi_bases ) muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim \\ = mus_sim . unpack () poisson_discrepancy = poisson_results . print_results ( lambda_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ) )","title":"An example"},{"location":"choo_siow/","text":"choo_siow module \u00b6 The components of the derivative of the entropy for the Choo and Siow homoskedastic model. e0_derivative_choo_siow ( muhat ) \u00b6 Returns the derivatives of $e_0$ for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the three components of the hessian wrt $(\\mu,\\mu)$ of the entropy and the two components of the hessian wrt $(\\mu,r)$ Source code in cupid_matching/choo_siow.py def e0_derivative_choo_siow ( muhat : Matching ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of $e_0$ for the Choo and Siow model. Args: muhat: a Matching Returns: the three components of the hessian wrt $(\\mu,\\mu)$ of the entropy and the two components of the hessian wrt $(\\mu,r)$ \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 2 ) hessmumu = entropy_res [ 2 ] hessmur = entropy_res [ 3 ] muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) hess_nx = np . zeros (( X , Y )) hess_my = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2xy = hessmumu [ x , y , :, :] d2r = hessmur [ x , y , :] hess_x [ x , y , :] = d2xy [ x , :] hess_y [ x , y , :] = d2xy [:, y ] hess_xy [ x , y ] = d2xy [ x , y ] hess_nx [ x , y ] = d2r [ x ] hess_my [ x , y ] = d2r [ X + y ] return ( hess_x , hess_y , hess_xy ), ( hess_nx , hess_my ) e0_fun_choo_siow ( muhat ) \u00b6 Returns the values of $e_0$ for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ndarray the (X,Y) matrix of the first derivative of the entropy Source code in cupid_matching/choo_siow.py def e0_fun_choo_siow ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of $e_0$ for the Choo and Siow model. Args: muhat: a Matching Returns: the (X,Y) matrix of the first derivative of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 1 ) return entropy_res [ 1 ]","title":"choo_siow"},{"location":"choo_siow/#choo_siow-module","text":"The components of the derivative of the entropy for the Choo and Siow homoskedastic model.","title":"choo_siow module"},{"location":"choo_siow/#cupid_matching.choo_siow.e0_derivative_choo_siow","text":"Returns the derivatives of $e_0$ for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the three components of the hessian wrt $(\\mu,\\mu)$ of the entropy and the two components of the hessian wrt $(\\mu,r)$ Source code in cupid_matching/choo_siow.py def e0_derivative_choo_siow ( muhat : Matching ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of $e_0$ for the Choo and Siow model. Args: muhat: a Matching Returns: the three components of the hessian wrt $(\\mu,\\mu)$ of the entropy and the two components of the hessian wrt $(\\mu,r)$ \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 2 ) hessmumu = entropy_res [ 2 ] hessmur = entropy_res [ 3 ] muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) hess_nx = np . zeros (( X , Y )) hess_my = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2xy = hessmumu [ x , y , :, :] d2r = hessmur [ x , y , :] hess_x [ x , y , :] = d2xy [ x , :] hess_y [ x , y , :] = d2xy [:, y ] hess_xy [ x , y ] = d2xy [ x , y ] hess_nx [ x , y ] = d2r [ x ] hess_my [ x , y ] = d2r [ X + y ] return ( hess_x , hess_y , hess_xy ), ( hess_nx , hess_my )","title":"e0_derivative_choo_siow()"},{"location":"choo_siow/#cupid_matching.choo_siow.e0_fun_choo_siow","text":"Returns the values of $e_0$ for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ndarray the (X,Y) matrix of the first derivative of the entropy Source code in cupid_matching/choo_siow.py def e0_fun_choo_siow ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of $e_0$ for the Choo and Siow model. Args: muhat: a Matching Returns: the (X,Y) matrix of the first derivative of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 1 ) return entropy_res [ 1 ]","title":"e0_fun_choo_siow()"},{"location":"choo_siow_gender_heteroskedastic/","text":"choo_siow_gender_heteroskedastic module \u00b6 The components of the derivative of the entropy for the Choo and Siow gender-heteroskedastic model. We normalize the standard error for the X side at 1, and we estimate the standard error on the Y side. e0_choo_siow_gender_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ndarray the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py def e0_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" muxy , mux0 , * _ = muhat . unpack () e0_vals = - np . log ( muxy / mux0 . reshape (( - 1 , 1 ))) return e0_vals e0_derivative_choo_siow_gender_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-independent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py def e0_derivative_choo_siow_gender_heteroskedastic ( muhat : Matching , ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the components of the parameter-independent part of the hessian of the entropy. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 for x in range ( X ): dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_x [ x , y , :] = - dlogx0 hess_xy [ x , y ] = - der_logxy [ x , y ] - dlogx0 hess_n [ x , y ] = dlogx0 return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m ) e_choo_siow_gender_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ndarray the (X,Y,1) array of the parameter-dependent part of the first derivative of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py def e_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y,1) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 e_vals = np . zeros (( X , Y , n_alpha )) e_vals [:, :, 0 ] = - np . log ( muxy / mu0y ) return e_vals e_derivative_choo_siow_gender_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-dependent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py def e_derivative_choo_siow_gender_heteroskedastic ( muhat : Matching , ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Args: muhat: a Matching Returns: the components of the parameter-dependent part of the hessian of the entropy. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_log0y = 1.0 / mu0y for x in range ( X ): for y in range ( Y ): dlog0y = der_log0y [ y ] hess_y [ x , y , :, 0 ] = - dlog0y hess_xy [ x , y , 0 ] = - der_logxy [ x , y ] - dlog0y hess_m [ x , y , 0 ] = dlog0y return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m )","title":"choo_siow_gender_heteroskedastic"},{"location":"choo_siow_gender_heteroskedastic/#choo_siow_gender_heteroskedastic-module","text":"The components of the derivative of the entropy for the Choo and Siow gender-heteroskedastic model. We normalize the standard error for the X side at 1, and we estimate the standard error on the Y side.","title":"choo_siow_gender_heteroskedastic module"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e0_choo_siow_gender_heteroskedastic","text":"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ndarray the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py def e0_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" muxy , mux0 , * _ = muhat . unpack () e0_vals = - np . log ( muxy / mux0 . reshape (( - 1 , 1 ))) return e0_vals","title":"e0_choo_siow_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e0_derivative_choo_siow_gender_heteroskedastic","text":"Returns the derivatives of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-independent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py def e0_derivative_choo_siow_gender_heteroskedastic ( muhat : Matching , ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the components of the parameter-independent part of the hessian of the entropy. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 for x in range ( X ): dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_x [ x , y , :] = - dlogx0 hess_xy [ x , y ] = - der_logxy [ x , y ] - dlogx0 hess_n [ x , y ] = dlogx0 return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m )","title":"e0_derivative_choo_siow_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e_choo_siow_gender_heteroskedastic","text":"Returns the values of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ndarray the (X,Y,1) array of the parameter-dependent part of the first derivative of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py def e_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y,1) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 e_vals = np . zeros (( X , Y , n_alpha )) e_vals [:, :, 0 ] = - np . log ( muxy / mu0y ) return e_vals","title":"e_choo_siow_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e_derivative_choo_siow_gender_heteroskedastic","text":"Returns the derivatives of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-dependent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py def e_derivative_choo_siow_gender_heteroskedastic ( muhat : Matching , ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Args: muhat: a Matching Returns: the components of the parameter-dependent part of the hessian of the entropy. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_log0y = 1.0 / mu0y for x in range ( X ): for y in range ( Y ): dlog0y = der_log0y [ y ] hess_y [ x , y , :, 0 ] = - dlog0y hess_xy [ x , y , 0 ] = - der_logxy [ x , y ] - dlog0y hess_m [ x , y , 0 ] = dlog0y return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m )","title":"e_derivative_choo_siow_gender_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/","text":"choo_siow_heteroskedastic module \u00b6 The components of the derivative of the entropy for the Choo and Siow fully heteroskedastic model. We normalize the standard error for X=1 at 1, and we estimate the standard errors for all other types on the X side and for all types on the Y side. e0_choo_siow_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ndarray the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy Source code in cupid_matching/choo_siow_heteroskedastic.py def e0_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy \"\"\" muxy , mux0 , mu0y , n , m = muhat . unpack () mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] e0_vals = np . zeros_like ( muxy ) e0_vals [ 0 , :] = - np . log ( mu1y / mu10 ) return e0_vals e0_derivative_choo_siow_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-independent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_heteroskedastic.py def e0_derivative_choo_siow_heteroskedastic ( muhat : Matching , ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the components of the parameter-independent part of the hessian of the entropy. \"\"\" muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_log1y = 1.0 / mu1y der_log10 = 1.0 / mu10 for y in range ( Y ): hess_x [ 0 , y , :] = - der_log10 hess_n [ 0 , y ] = der_log10 hess_xy [ 0 , y ] = - der_log1y [ y ] - der_log10 return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m ) e_choo_siow_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ndarray the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_heteroskedastic.py def e_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. \"\"\" muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 e_vals = np . zeros (( X , Y , n_alpha )) i = 0 for x in range ( 1 , X ): e_vals [ x , :, i ] = - np . log ( muxy [ x , :] / mux0 [ x ]) i += 1 for y in range ( Y ): e_vals [:, y , i ] = - np . log ( muxy [:, y ] / mu0y [ y ]) i += 1 return e_vals e_derivative_choo_siow_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-dependent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_heteroskedastic.py def e_derivative_choo_siow_heteroskedastic ( muhat : Matching ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the components of the parameter-dependent part of the hessian of the entropy. \"\"\" muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y i = 0 for x in range ( 1 , X ): # derivatives wrt sigma_x dlogx0 = der_logx0 [ x ] dlogxy = der_logxy [ x , :] for y in range ( Y ): hess_x [ x , y , :, i ] = - dlogx0 hess_xy [ x , y , i ] = - dlogxy [ y ] - dlogx0 hess_n [ x , y , i ] = dlogx0 i += 1 for y in range ( Y ): # derivatives wrt tau_y dlog0y = der_log0y [ y ] dlogxy = der_logxy [:, y ] for x in range ( X ): hess_y [ x , y , :, i ] = - dlog0y hess_xy [ x , y , i ] = - dlogxy [ x ] - dlog0y hess_m [ x , y , i ] = dlog0y i += 1 return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m )","title":"choo_siow_heteroskedastic"},{"location":"choo_siow_heteroskedastic/#choo_siow_heteroskedastic-module","text":"The components of the derivative of the entropy for the Choo and Siow fully heteroskedastic model. We normalize the standard error for X=1 at 1, and we estimate the standard errors for all other types on the X side and for all types on the Y side.","title":"choo_siow_heteroskedastic module"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e0_choo_siow_heteroskedastic","text":"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ndarray the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy Source code in cupid_matching/choo_siow_heteroskedastic.py def e0_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy \"\"\" muxy , mux0 , mu0y , n , m = muhat . unpack () mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] e0_vals = np . zeros_like ( muxy ) e0_vals [ 0 , :] = - np . log ( mu1y / mu10 ) return e0_vals","title":"e0_choo_siow_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e0_derivative_choo_siow_heteroskedastic","text":"Returns the derivatives of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-independent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_heteroskedastic.py def e0_derivative_choo_siow_heteroskedastic ( muhat : Matching , ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the components of the parameter-independent part of the hessian of the entropy. \"\"\" muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_log1y = 1.0 / mu1y der_log10 = 1.0 / mu10 for y in range ( Y ): hess_x [ 0 , y , :] = - der_log10 hess_n [ 0 , y ] = der_log10 hess_xy [ 0 , y ] = - der_log1y [ y ] - der_log10 return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m )","title":"e0_derivative_choo_siow_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e_choo_siow_heteroskedastic","text":"Returns the values of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ndarray the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_heteroskedastic.py def e_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. \"\"\" muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 e_vals = np . zeros (( X , Y , n_alpha )) i = 0 for x in range ( 1 , X ): e_vals [ x , :, i ] = - np . log ( muxy [ x , :] / mux0 [ x ]) i += 1 for y in range ( Y ): e_vals [:, y , i ] = - np . log ( muxy [:, y ] / mu0y [ y ]) i += 1 return e_vals","title":"e_choo_siow_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e_derivative_choo_siow_heteroskedastic","text":"Returns the derivatives of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-dependent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_heteroskedastic.py def e_derivative_choo_siow_heteroskedastic ( muhat : Matching ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the components of the parameter-dependent part of the hessian of the entropy. \"\"\" muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y i = 0 for x in range ( 1 , X ): # derivatives wrt sigma_x dlogx0 = der_logx0 [ x ] dlogxy = der_logxy [ x , :] for y in range ( Y ): hess_x [ x , y , :, i ] = - dlogx0 hess_xy [ x , y , i ] = - dlogxy [ y ] - dlogx0 hess_n [ x , y , i ] = dlogx0 i += 1 for y in range ( Y ): # derivatives wrt tau_y dlog0y = der_log0y [ y ] dlogxy = der_logxy [:, y ] for x in range ( X ): hess_y [ x , y , :, i ] = - dlog0y hess_xy [ x , y , i ] = - dlogxy [ x ] - dlog0y hess_m [ x , y , i ] = dlog0y i += 1 return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m )","title":"e_derivative_choo_siow_heteroskedastic()"},{"location":"entropy/","text":"entropy module \u00b6 Entropies of some useful models. EntropyGradient \u00b6 The type of a function that takes in a Matching and possibly a list of other parameters and returns an array with the gradient of entropy wrt $\\mu$. EntropyHessianComponents \u00b6 combines the tuples of components of the hessians EntropyHessianComponentsMuMu \u00b6 The type of a tuple of the three components of the hessian of the entropy wrt $(\\mu,\\mu)$. EntropyHessianComponentsMuR \u00b6 The type of a tuple of the two components of the hessian of the entropy wrt $(\\mu,n)$ and $(\\mu, m))$. EntropyHessianMuMu \u00b6 The type of a function that takes in a Matching and returns the three components of the hessian of the entropy wrt $(\\mu,\\mu)$. EntropyHessianMuR \u00b6 The type of a function that takes in a Matching and returns the two components of the hessian of the entropy wrt $(\\mu,n)$ and $(\\mu, m))$. EntropyHessians \u00b6 combines the hessians EntropyFunctions dataclass \u00b6 Defines the entropy used, via the derivative $e_0 + e \\cdot \\alpha$ Attributes: Name Type Description e0_fun Callable[[cupid_matching.matching_utils.Matching, Optional[List]], numpy.ndarray] required parameter_dependent Optional[bool] if True , the entropy depends on parameters. Defaults to False e_fun Optional[Callable[[cupid_matching.matching_utils.Matching, Union[List, NoneType]], numpy.ndarray]] only in entropies that depend on parameters. Defaults to None hessian Optional[str] defaults to \"numeric\" * if \"provide\" , we provide the hessian of the entropy. * if \"numerical\" , it is computed by central differences. e0_derivative Optional[Tuple[Callable[[cupid_matching.matching_utils.Matching], Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]], Callable[[cupid_matching.matching_utils.Matching], Tuple[numpy.ndarray, numpy.ndarray]]]] the derivative of e0_fun , if available. Defaults to None e_derivative Optional[Tuple[Callable[[cupid_matching.matching_utils.Matching], Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]], Callable[[cupid_matching.matching_utils.Matching], Tuple[numpy.ndarray, numpy.ndarray]]]] the derivative of e_fun , if available. Defaults to None more_params Optional[List] additional parameters that define the distribution of errors. Defaults to None description Optional[str] some text describing the model. Defaults to None Examples: See entropy_choo_siow in choo_siow.py Source code in cupid_matching/entropy.py class EntropyFunctions : \"\"\"Defines the entropy used, via the derivative $e_0 + e \\cdot \\\\alpha$ Attributes: e0_fun: required parameter_dependent: if `True`, the entropy depends on parameters. Defaults to `False` e_fun: only in entropies that depend on parameters. Defaults to `None` hessian: defaults to `\"numeric\"` * if `\"provide\"`, we provide the hessian of the entropy. * if `\"numerical\"`, it is computed by central differences. e0_derivative: the derivative of `e0_fun`, if available. Defaults to `None` e_derivative: the derivative of `e_fun`, if available. Defaults to `None` more_params: additional parameters that define the distribution of errors. Defaults to `None` description: some text describing the model. Defaults to `None` Examples: See `entropy_choo_siow` in `choo_siow.py` \"\"\" e0_fun : EntropyGradient parameter_dependent : Optional [ bool ] = False e_fun : Optional [ EntropyGradient ] = None hessian : Optional [ str ] = \"numerical\" e0_derivative : Optional [ EntropyHessians ] = None e_derivative : Optional [ EntropyHessians ] = None more_params : Optional [ List ] = None description : Optional [ str ] = None def __post_init__ ( self ): if not self . parameter_dependent : if self . hessian == \"provided\" and self . e0_derivative is None : bs_error_abort ( \"You claim to provide the hessian \" + \"but you did not provide the e0_derivative.\" ) else : if self . e_fun is None : bs_error_abort ( \"Your entropy is parameter dependent \" + \" but you did not provide the e_fun.\" ) if self . hessian == \"provided\" and self . e_derivative is None : bs_error_abort ( \"Your entropy is parameter dependent, \" + \"you claim to provide the hessian, \\n \" + \" but I do not see the e_derivative.\" ) entropy_gradient ( entropy , muhat , alpha = None , more_params = None ) \u00b6 Computes the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \u0007lpha)$ Parameters: Name Type Description Default entropy EntropyFunctions the EntropyFunctions object required muhat Matching a Matching required alpha Optional[numpy.ndarray] a vector of parameters of the derivative of the entropy, if any None more_params Optional[List] a list of additional parameters, if any None Returns: Type Description ndarray the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \u0007lpha)$. Source code in cupid_matching/entropy.py def entropy_gradient ( entropy : EntropyFunctions , muhat : Matching , alpha : Optional [ np . ndarray ] = None , more_params : Optional [ List ] = None , ) -> np . ndarray : \"\"\"Computes the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \\alpha)$ Args: entropy: the `EntropyFunctions` object muhat: a Matching alpha: a vector of parameters of the derivative of the entropy, if any more_params: a list of additional parameters, if any Returns: the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \\alpha)$. \"\"\" e0_fun = entropy . e0_fun if more_params is None : e0_vals = e0_fun ( muhat ) else : e0_vals = e0_fun ( muhat , more_params = more_params ) parameter_dependent = entropy . parameter_dependent if parameter_dependent : if alpha is None : bs_error_abort ( \"alpha should be specified for this model\" ) e_fun = entropy . e_fun if more_params is None : e_vals = e_fun ( muhat ) else : e_vals = e_fun ( muhat , more_params = more_params ) return e0_vals + e_vals @ alpha else : return e0_vals","title":"entropy"},{"location":"entropy/#entropy-module","text":"Entropies of some useful models.","title":"entropy module"},{"location":"entropy/#cupid_matching.entropy.EntropyGradient","text":"The type of a function that takes in a Matching and possibly a list of other parameters and returns an array with the gradient of entropy wrt $\\mu$.","title":"EntropyGradient"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianComponents","text":"combines the tuples of components of the hessians","title":"EntropyHessianComponents"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianComponentsMuMu","text":"The type of a tuple of the three components of the hessian of the entropy wrt $(\\mu,\\mu)$.","title":"EntropyHessianComponentsMuMu"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianComponentsMuR","text":"The type of a tuple of the two components of the hessian of the entropy wrt $(\\mu,n)$ and $(\\mu, m))$.","title":"EntropyHessianComponentsMuR"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianMuMu","text":"The type of a function that takes in a Matching and returns the three components of the hessian of the entropy wrt $(\\mu,\\mu)$.","title":"EntropyHessianMuMu"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianMuR","text":"The type of a function that takes in a Matching and returns the two components of the hessian of the entropy wrt $(\\mu,n)$ and $(\\mu, m))$.","title":"EntropyHessianMuR"},{"location":"entropy/#cupid_matching.entropy.EntropyHessians","text":"combines the hessians","title":"EntropyHessians"},{"location":"entropy/#cupid_matching.entropy.EntropyFunctions","text":"Defines the entropy used, via the derivative $e_0 + e \\cdot \\alpha$ Attributes: Name Type Description e0_fun Callable[[cupid_matching.matching_utils.Matching, Optional[List]], numpy.ndarray] required parameter_dependent Optional[bool] if True , the entropy depends on parameters. Defaults to False e_fun Optional[Callable[[cupid_matching.matching_utils.Matching, Union[List, NoneType]], numpy.ndarray]] only in entropies that depend on parameters. Defaults to None hessian Optional[str] defaults to \"numeric\" * if \"provide\" , we provide the hessian of the entropy. * if \"numerical\" , it is computed by central differences. e0_derivative Optional[Tuple[Callable[[cupid_matching.matching_utils.Matching], Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]], Callable[[cupid_matching.matching_utils.Matching], Tuple[numpy.ndarray, numpy.ndarray]]]] the derivative of e0_fun , if available. Defaults to None e_derivative Optional[Tuple[Callable[[cupid_matching.matching_utils.Matching], Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]], Callable[[cupid_matching.matching_utils.Matching], Tuple[numpy.ndarray, numpy.ndarray]]]] the derivative of e_fun , if available. Defaults to None more_params Optional[List] additional parameters that define the distribution of errors. Defaults to None description Optional[str] some text describing the model. Defaults to None Examples: See entropy_choo_siow in choo_siow.py Source code in cupid_matching/entropy.py class EntropyFunctions : \"\"\"Defines the entropy used, via the derivative $e_0 + e \\cdot \\\\alpha$ Attributes: e0_fun: required parameter_dependent: if `True`, the entropy depends on parameters. Defaults to `False` e_fun: only in entropies that depend on parameters. Defaults to `None` hessian: defaults to `\"numeric\"` * if `\"provide\"`, we provide the hessian of the entropy. * if `\"numerical\"`, it is computed by central differences. e0_derivative: the derivative of `e0_fun`, if available. Defaults to `None` e_derivative: the derivative of `e_fun`, if available. Defaults to `None` more_params: additional parameters that define the distribution of errors. Defaults to `None` description: some text describing the model. Defaults to `None` Examples: See `entropy_choo_siow` in `choo_siow.py` \"\"\" e0_fun : EntropyGradient parameter_dependent : Optional [ bool ] = False e_fun : Optional [ EntropyGradient ] = None hessian : Optional [ str ] = \"numerical\" e0_derivative : Optional [ EntropyHessians ] = None e_derivative : Optional [ EntropyHessians ] = None more_params : Optional [ List ] = None description : Optional [ str ] = None def __post_init__ ( self ): if not self . parameter_dependent : if self . hessian == \"provided\" and self . e0_derivative is None : bs_error_abort ( \"You claim to provide the hessian \" + \"but you did not provide the e0_derivative.\" ) else : if self . e_fun is None : bs_error_abort ( \"Your entropy is parameter dependent \" + \" but you did not provide the e_fun.\" ) if self . hessian == \"provided\" and self . e_derivative is None : bs_error_abort ( \"Your entropy is parameter dependent, \" + \"you claim to provide the hessian, \\n \" + \" but I do not see the e_derivative.\" )","title":"EntropyFunctions"},{"location":"entropy/#cupid_matching.entropy.entropy_gradient","text":"Computes the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \u0007lpha)$ Parameters: Name Type Description Default entropy EntropyFunctions the EntropyFunctions object required muhat Matching a Matching required alpha Optional[numpy.ndarray] a vector of parameters of the derivative of the entropy, if any None more_params Optional[List] a list of additional parameters, if any None Returns: Type Description ndarray the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \u0007lpha)$. Source code in cupid_matching/entropy.py def entropy_gradient ( entropy : EntropyFunctions , muhat : Matching , alpha : Optional [ np . ndarray ] = None , more_params : Optional [ List ] = None , ) -> np . ndarray : \"\"\"Computes the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \\alpha)$ Args: entropy: the `EntropyFunctions` object muhat: a Matching alpha: a vector of parameters of the derivative of the entropy, if any more_params: a list of additional parameters, if any Returns: the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \\alpha)$. \"\"\" e0_fun = entropy . e0_fun if more_params is None : e0_vals = e0_fun ( muhat ) else : e0_vals = e0_fun ( muhat , more_params = more_params ) parameter_dependent = entropy . parameter_dependent if parameter_dependent : if alpha is None : bs_error_abort ( \"alpha should be specified for this model\" ) e_fun = entropy . e_fun if more_params is None : e_vals = e_fun ( muhat ) else : e_vals = e_fun ( muhat , more_params = more_params ) return e0_vals + e_vals @ alpha else : return e0_vals","title":"entropy_gradient()"},{"location":"ipfp_solvers/","text":"ipfp_solvers module \u00b6 Implementations of the IPFP algorithm to solve for equilibrium and do comparative statics in several variants of the Choo and Siow 2006 <https://www.jstor.org/stable/10.1086/498585?seq=1> _ model: homoskedastic with singles (as in Choo and Siow 2006) homoskedastic without singles gender-heteroskedastic: with a scale parameter on the error term for women gender- and type-heteroskedastic: with a scale parameter on the error term for each gender and type two-level nested logit, with nests and nest parameters that do not depend on the type, and {0} as the first nest Each solver, when fed the joint surplus and margins, returns the equilibrium matching patterns, the adding-up errors on the margins, and if requested (using gr=True ) the derivatives of the matching patterns in all primitives. ipfp_gender_heteroskedastic_solver ( Phi , men_margins , women_margins , tau , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter tau Parameters: Name Type Description Default Phi <built-in function array> matrix of systematic surplus, shape (X, Y) required men_margins <built-in function array> vector of men margins, shape (X) required women_margins <built-in function array> vector of women margins, shape (Y) required tau float the standard error for all women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description (muxy, mux0, mu0y) the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, tau) if gr is True Source code in cupid_matching/ipfp_solvers.py def ipfp_gender_heteroskedastic_solver ( Phi : np . array , men_margins : np . array , women_margins : np . array , tau : float , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPResults : \"\"\"Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter `tau` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tau: the standard error for all women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, tau) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if tau <= 0 : bs_error_abort ( f \"We need a positive tau, not { tau } \" ) ############################################################################# # we use ipfp_heteroxy_solver with sigma_x = 1 and tau_y = tau ############################################################################# sigma_x = np . ones ( X ) tau_y = np . full ( Y , tau ) if gr : mus_hxy , marg_err_x , marg_err_y , dmus_hxy = ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = True , maxiter = maxiter , verbose = verbose , ) muxy , mux0 , mu0y = mus_hxy dmus_xy , dmus_x0 , dmus_0y = dmus_hxy n_sum_categories = X + Y n_prod_categories = X * Y n_cols = n_sum_categories + n_prod_categories itau_y = n_cols + X dmuxy = np . zeros (( n_prod_categories , n_cols + 1 )) dmuxy [:, : n_cols ] = dmus_xy [:, : n_cols ] dmuxy [:, - 1 ] = np . sum ( dmus_xy [:, itau_y :], 1 ) dmux0 = np . zeros (( X , n_cols + 1 )) dmux0 [:, : n_cols ] = dmus_x0 [:, : n_cols ] dmux0 [:, - 1 ] = np . sum ( dmus_x0 [:, itau_y :], 1 ) dmu0y = np . zeros (( Y , n_cols + 1 )) dmu0y [:, : n_cols ] = dmus_0y [:, : n_cols ] dmu0y [:, - 1 ] = np . sum ( dmus_0y [:, itau_y :], 1 ) return ( muxy , mux0 , mu0y ), marg_err_x , marg_err_y , ( dmuxy , dmux0 , dmu0y ) else : return ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = False , maxiter = maxiter , verbose = verbose , ) ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors sigma_x and tau_y Parameters: Name Type Description Default Phi <built-in function array> matrix of systematic surplus, shape (X, Y) required men_margins <built-in function array> vector of men margins, shape (X) required women_margins <built-in function array> vector of women margins, shape (Y) required sigma_x <built-in function array> the vector of standard errors for the X types of men required sigma_x <built-in function array> the vector of standard errors for Y types of women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description (muxy, mux0, mu0y) the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, sigma_x, tau_y) if gr is True Source code in cupid_matching/ipfp_solvers.py def ipfp_heteroskedastic_solver ( Phi : np . array , men_margins : np . array , women_margins : np . array , sigma_x : np . array , tau_y : np . array , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPResults : \"\"\"Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors `sigma_x` and `tau_y` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) sigma_x: the vector of standard errors for the X types of men sigma_x: the vector of standard errors for Y types of women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, sigma_x, tau_y) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if np . min ( sigma_x ) <= 0.0 : bs_error_abort ( \"All elements of sigma_x must be positive\" ) if np . min ( tau_y ) <= 0.0 : bs_error_abort ( \"All elements of tau_y must be positive\" ) sumxy1 = 1.0 / np . add . outer ( sigma_x , tau_y ) ephi2 , der_ephi2 = npexp ( Phi * sumxy1 , deriv = True ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # with tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi2 )) # we find the largest values of sigma_x and tau_y xmax = np . argmax ( sigma_x ) sigma_max = sigma_x [ xmax ] ymax = np . argmax ( tau_y ) tau_max = tau_y [ ymax ] # we use tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) sig_taumax = sigma_x + tau_max txi = np . power ( bigc , sigma_x / sig_taumax ) sigmax_tau = tau_y + sigma_max tyi = np . power ( bigc , tau_y / sigmax_tau ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc txin = txi . copy () mu0y_in = np . power ( np . power ( tyi , sigmax_tau ), 1.0 / tau_y ) while err_newton > tol_newton : txit = np . power ( txin , sig_taumax ) mux0_in = np . power ( txit , 1.0 / sigma_x ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y )) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) errxi = mux0_in + np . sum ( muxy_in , 1 ) - men_margins err_newton = npmaxabs ( errxi ) txin -= errxi / ( sig_taumax * ( mux0_in / sigma_x + np . sum ( sumxy1 * muxy_in , 1 )) / txin ) tx = txin # Newton iterates for women err_newton = bigc tyin = tyi . copy () mux0_in = np . power ( np . power ( tx , sig_taumax ), 1.0 / sigma_x ) while err_newton > tol_newton : tyit = np . power ( tyin , sigmax_tau ) mu0y_in = np . power ( tyit , 1.0 / tau_y ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y )) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) erryi = mu0y_in + np . sum ( muxy_in , 0 ) - women_margins err_newton = npmaxabs ( erryi ) tyin -= erryi / ( sigmax_tau * ( mu0y_in / tau_y + np . sum ( sumxy1 * muxy_in , 0 )) / tyin ) ty = tyin err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = mux0_in mu0y = mu0y_in muxy = muxy_in marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( muxy , mux0 , mu0y ), marg_err_x , marg_err_y else : # we compute the derivatives n_sum_categories = X + Y n_prod_categories = X * Y # we work directly with (mux0, mu0y) sigrat_xy = sumxy1 * sigma_x . reshape (( - 1 , 1 )) taurat_xy = 1.0 - sigrat_xy mux0_mat = nprepeat_col ( mux0 , Y ) mu0y_mat = nprepeat_row ( mu0y , X ) # muxy = axy * bxy * ephi2 axy = nppow ( mux0_mat , sigrat_xy ) bxy = nppow ( mu0y_mat , taurat_xy ) der_axy1 , der_axy2 = der_nppow ( mux0_mat , sigrat_xy ) der_bxy1 , der_bxy2 = der_nppow ( mu0y_mat , taurat_xy ) der_axy1_rat , der_axy2_rat = der_axy1 / axy , der_axy2 / axy der_bxy1_rat , der_bxy2_rat = der_bxy1 / bxy , der_bxy2 / bxy # start with the LHS of the linear system on (dmux0, dmu0y) lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 1.0 + np . sum ( muxy * der_axy1_rat , 1 )) lhs [: X , X :] = muxy * der_bxy1_rat lhs [ X :, X :] = np . diag ( 1.0 + np . sum ( muxy * der_bxy1_rat , 0 )) lhs [ X :, : X ] = ( muxy * der_axy1_rat ) . T # now fill the RHS (derivatives wrt men_margins, then men_margins, # then Phi, then sigma_x and tau_y) n_cols_rhs = n_sum_categories + n_prod_categories + X + Y rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (mux0, mu0y) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute derivatives of (mux0, mu0y) wrt women_margins rhs [ X :, X : n_sum_categories ] = np . eye ( Y ) # the next line is sumxy1 with safeguards sumxy1_safe = sumxy1 * der_ephi2 / ephi2 big_a = muxy * sumxy1_safe big_b = der_axy2_rat - der_bxy2_rat b_mu_s = big_b * muxy * sumxy1 a_phi = Phi * big_a big_c = sumxy1 * ( a_phi - b_mu_s * tau_y ) big_d = sumxy1 * ( a_phi + b_mu_s * sigma_x . reshape (( - 1 , 1 ))) # to compute derivatives of (mux0, mu0y) wrt Phi ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - big_a [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories iend_phi = n_sum_categories + n_prod_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : iend_phi : Y ] = - big_a [:, iwoman ] ivar1 += 1 ivar2 += 1 # to compute derivatives of (mux0, mu0y) wrt sigma_x iend_sig = iend_phi + X der_sigx = np . sum ( big_c , 1 ) rhs [: X , iend_phi : iend_sig ] = np . diag ( der_sigx ) rhs [ X :, iend_phi : iend_sig ] = big_c . T # to compute derivatives of (mux0, mu0y) wrt tau_y der_tauy = np . sum ( big_d , 0 ) rhs [ X :, iend_sig :] = np . diag ( der_tauy ) rhs [: X , iend_sig :] = big_d # solve for the derivatives of mux0 and mu0y dmu0 = spla . solve ( lhs , rhs ) dmux0 = dmu0 [: X , :] dmu0y = dmu0 [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) der1 = ephi2 * der_axy1 * bxy ivar = 0 for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), :] = np . outer ( der1 [ iman , :], dmux0 [ iman , :]) ivar += Y der2 = ephi2 * der_bxy1 * axy for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( der2 [:, iwoman ], dmu0y [ iwoman , :] ) # add the terms that comes from differentiating ephi2 # on the derivative wrt Phi i = 0 j = n_sum_categories for iman in range ( X ): for iwoman in range ( Y ): dmuxy [ i , j ] += big_a [ iman , iwoman ] i += 1 j += 1 # on the derivative wrt sigma_x ivar = 0 ix = iend_phi for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), ix ] -= big_c [ iman , :] ivar += Y ix += 1 # on the derivative wrt tau_y iy = iend_sig for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , iy ] -= big_d [:, iwoman ] iy += 1 return ( muxy , mux0 , mu0y ), marg_err_x , marg_err_y , ( dmuxy , dmux0 , dmu0y ) ipfp_homoskedastic_nosingles_solver ( Phi , men_margins , women_margins , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Parameters: Name Type Description Default Phi <built-in function array> matrix of systematic surplus, shape (X, Y) required men_margins <built-in function array> vector of men margins, shape (X) required women_margins <built-in function array> vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of $(\\mu_{xy})$ wrt $\\Phi$ False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy the matching patterns, shape (X, Y) marg_err_x, marg_err_y: the errors on the margins and the gradients of $(\\mu_{xy})$ wrt $\\Phi$ if gr is True Source code in cupid_matching/ipfp_solvers.py def ipfp_homoskedastic_nosingles_solver ( Phi : np . array , men_margins : np . array , women_margins : np . array , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPResults : \"\"\"Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of $(\\mu_{xy})$ wrt $\\Phi$ verbose: if `True`, prints information maxiter: maximum number of iterations Returns: muxy: the matching patterns, shape (X, Y) marg_err_x, marg_err_y: the errors on the margins and the gradients of $(\\mu_{xy})$ wrt $\\Phi$ if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) n_couples = np . sum ( men_margins ) # check that there are as many men as women if np . abs ( np . sum ( women_margins ) - n_couples ) > n_couples * tol : bs_error_abort ( \"There should be as many men as women\" ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = True ) ephi2T = ephi2 . T ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # starting with a reasonable initial point for tx and ty: : tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# bigc = sqrt ( n_couples / np . sum ( ephi2 )) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * err_diff niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = men_margins / sx sy = ephi2T @ tx ty = women_margins / sy err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi , tyi = tx , ty niter += 1 muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = np . sum ( muxy , 1 ) - men_margins marg_err_y = np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return muxy , marg_err_x , marg_err_y else : sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = 0 for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = 0 for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer (( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy += np . diag ( muxy_vec2 ) return muxy , marg_err_x , marg_err_y , dmuxy ipfp_homoskedastic_solver ( Phi , men_margins , women_margins , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Parameters: Name Type Description Default Phi <built-in function array> matrix of systematic surplus, shape (X, Y) required men_margins <built-in function array> vector of men margins, shape (X) required women_margins <built-in function array> vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description (muxy, mux0, mu0y) the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) if gr is True Examples: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu , sigma = 0.0 , 1.0 n_bases = 4 bases_surplus = np . zeros (( X , Y , n_bases )) x_men = ( np . arange ( X ) - X / 2.0 ) / X y_women = ( np . arange ( Y ) - Y / 2.0 ) / Y bases_surplus [:, :, 0 ] = 1 for iy in range ( Y ): bases_surplus [:, iy , 1 ] = x_men for ix in range ( X ): bases_surplus [ ix , :, 2 ] = y_women for ix in range ( X ): for iy in range ( Y ): bases_surplus [ ix , iy , 3 ] = ( x_men [ ix ] - y_women [ iy ]) * ( x_men [ ix ] - y_women [ iy ] ) men_margins = np . random . uniform ( 1.0 , 10.0 , size = X ) women_margins = np . random . uniform ( 1.0 , 10.0 , size = Y ) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np . array ([ 3.0 , - 1.0 , - 1.0 , - 2.0 ]) true_surplus_matrix = bases_surplus @ true_surplus_params mus , marg_err_x , marg_err_y = ipfp_homoskedastic_solver ( true_surplus_matrix , men_margins , women_margins , tol = 1e-12 ) Source code in cupid_matching/ipfp_solvers.py def ipfp_homoskedastic_solver ( Phi : np . array , men_margins : np . array , women_margins : np . array , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPResults : \"\"\"Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) if `gr` is `True` Example: ```py # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu, sigma = 0.0, 1.0 n_bases = 4 bases_surplus = np.zeros((X, Y, n_bases)) x_men = (np.arange(X) - X / 2.0) / X y_women = (np.arange(Y) - Y / 2.0) / Y bases_surplus[:, :, 0] = 1 for iy in range(Y): bases_surplus[:, iy, 1] = x_men for ix in range(X): bases_surplus[ix, :, 2] = y_women for ix in range(X): for iy in range(Y): bases_surplus[ix, iy, 3] = (x_men[ix] - y_women[iy]) * ( x_men[ix] - y_women[iy] ) men_margins = np.random.uniform(1.0, 10.0, size=X) women_margins = np.random.uniform(1.0, 10.0, size=Y) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np.array([3.0, -1.0, -1.0, -2.0]) true_surplus_matrix = bases_surplus @ true_surplus_params mus, marg_err_x, marg_err_y = ipfp_homoskedastic_solver( true_surplus_matrix, men_margins, women_margins, tol=1e-12 ) ``` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = True ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # where mux0=tx**2 and mu0y=ty**2 # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# ephi2T = ephi2 . T nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = sqrt ( nindivs / ( X + Y + 2.0 * np . sum ( ephi2 ))) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * bigc niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = ( np . sqrt ( sx * sx + 4.0 * men_margins ) - sx ) / 2.0 sy = ephi2T @ tx ty = ( np . sqrt ( sy * sy + 4.0 * women_margins ) - sy ) / 2.0 err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = txi * txi mu0y = tyi * tyi muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( muxy , mux0 , mu0y ), marg_err_x , marg_err_y else : # we compute the derivatives sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 2.0 * txi + sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( 2.0 * tyi + syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_sum_categories + n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (txi, tyi) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute derivatives of (txi, tyi) wrt women_margins rhs [ X : n_sum_categories , X : n_sum_categories ] = np . eye ( Y ) # to compute derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of the mus dmux0 = 2.0 * ( dt * txi . reshape (( - 1 , 1 ))) dmu0y = 2.0 * ( dT * tyi . reshape (( - 1 , 1 ))) dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer (( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy [:, n_sum_categories :] += np . diag ( muxy_vec2 ) return ( muxy , mux0 , mu0y ), marg_err_x , marg_err_y , ( dmuxy , dmux0 , dmu0y )","title":"ipfp_solvers"},{"location":"ipfp_solvers/#ipfp_solvers-module","text":"Implementations of the IPFP algorithm to solve for equilibrium and do comparative statics in several variants of the Choo and Siow 2006 <https://www.jstor.org/stable/10.1086/498585?seq=1> _ model: homoskedastic with singles (as in Choo and Siow 2006) homoskedastic without singles gender-heteroskedastic: with a scale parameter on the error term for women gender- and type-heteroskedastic: with a scale parameter on the error term for each gender and type two-level nested logit, with nests and nest parameters that do not depend on the type, and {0} as the first nest Each solver, when fed the joint surplus and margins, returns the equilibrium matching patterns, the adding-up errors on the margins, and if requested (using gr=True ) the derivatives of the matching patterns in all primitives.","title":"ipfp_solvers module"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_gender_heteroskedastic_solver","text":"Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter tau Parameters: Name Type Description Default Phi <built-in function array> matrix of systematic surplus, shape (X, Y) required men_margins <built-in function array> vector of men margins, shape (X) required women_margins <built-in function array> vector of women margins, shape (Y) required tau float the standard error for all women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description (muxy, mux0, mu0y) the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, tau) if gr is True Source code in cupid_matching/ipfp_solvers.py def ipfp_gender_heteroskedastic_solver ( Phi : np . array , men_margins : np . array , women_margins : np . array , tau : float , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPResults : \"\"\"Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter `tau` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tau: the standard error for all women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, tau) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if tau <= 0 : bs_error_abort ( f \"We need a positive tau, not { tau } \" ) ############################################################################# # we use ipfp_heteroxy_solver with sigma_x = 1 and tau_y = tau ############################################################################# sigma_x = np . ones ( X ) tau_y = np . full ( Y , tau ) if gr : mus_hxy , marg_err_x , marg_err_y , dmus_hxy = ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = True , maxiter = maxiter , verbose = verbose , ) muxy , mux0 , mu0y = mus_hxy dmus_xy , dmus_x0 , dmus_0y = dmus_hxy n_sum_categories = X + Y n_prod_categories = X * Y n_cols = n_sum_categories + n_prod_categories itau_y = n_cols + X dmuxy = np . zeros (( n_prod_categories , n_cols + 1 )) dmuxy [:, : n_cols ] = dmus_xy [:, : n_cols ] dmuxy [:, - 1 ] = np . sum ( dmus_xy [:, itau_y :], 1 ) dmux0 = np . zeros (( X , n_cols + 1 )) dmux0 [:, : n_cols ] = dmus_x0 [:, : n_cols ] dmux0 [:, - 1 ] = np . sum ( dmus_x0 [:, itau_y :], 1 ) dmu0y = np . zeros (( Y , n_cols + 1 )) dmu0y [:, : n_cols ] = dmus_0y [:, : n_cols ] dmu0y [:, - 1 ] = np . sum ( dmus_0y [:, itau_y :], 1 ) return ( muxy , mux0 , mu0y ), marg_err_x , marg_err_y , ( dmuxy , dmux0 , dmu0y ) else : return ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = False , maxiter = maxiter , verbose = verbose , )","title":"ipfp_gender_heteroskedastic_solver()"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_heteroskedastic_solver","text":"Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors sigma_x and tau_y Parameters: Name Type Description Default Phi <built-in function array> matrix of systematic surplus, shape (X, Y) required men_margins <built-in function array> vector of men margins, shape (X) required women_margins <built-in function array> vector of women margins, shape (Y) required sigma_x <built-in function array> the vector of standard errors for the X types of men required sigma_x <built-in function array> the vector of standard errors for Y types of women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description (muxy, mux0, mu0y) the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, sigma_x, tau_y) if gr is True Source code in cupid_matching/ipfp_solvers.py def ipfp_heteroskedastic_solver ( Phi : np . array , men_margins : np . array , women_margins : np . array , sigma_x : np . array , tau_y : np . array , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPResults : \"\"\"Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors `sigma_x` and `tau_y` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) sigma_x: the vector of standard errors for the X types of men sigma_x: the vector of standard errors for Y types of women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, sigma_x, tau_y) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if np . min ( sigma_x ) <= 0.0 : bs_error_abort ( \"All elements of sigma_x must be positive\" ) if np . min ( tau_y ) <= 0.0 : bs_error_abort ( \"All elements of tau_y must be positive\" ) sumxy1 = 1.0 / np . add . outer ( sigma_x , tau_y ) ephi2 , der_ephi2 = npexp ( Phi * sumxy1 , deriv = True ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # with tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi2 )) # we find the largest values of sigma_x and tau_y xmax = np . argmax ( sigma_x ) sigma_max = sigma_x [ xmax ] ymax = np . argmax ( tau_y ) tau_max = tau_y [ ymax ] # we use tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) sig_taumax = sigma_x + tau_max txi = np . power ( bigc , sigma_x / sig_taumax ) sigmax_tau = tau_y + sigma_max tyi = np . power ( bigc , tau_y / sigmax_tau ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc txin = txi . copy () mu0y_in = np . power ( np . power ( tyi , sigmax_tau ), 1.0 / tau_y ) while err_newton > tol_newton : txit = np . power ( txin , sig_taumax ) mux0_in = np . power ( txit , 1.0 / sigma_x ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y )) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) errxi = mux0_in + np . sum ( muxy_in , 1 ) - men_margins err_newton = npmaxabs ( errxi ) txin -= errxi / ( sig_taumax * ( mux0_in / sigma_x + np . sum ( sumxy1 * muxy_in , 1 )) / txin ) tx = txin # Newton iterates for women err_newton = bigc tyin = tyi . copy () mux0_in = np . power ( np . power ( tx , sig_taumax ), 1.0 / sigma_x ) while err_newton > tol_newton : tyit = np . power ( tyin , sigmax_tau ) mu0y_in = np . power ( tyit , 1.0 / tau_y ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y )) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) erryi = mu0y_in + np . sum ( muxy_in , 0 ) - women_margins err_newton = npmaxabs ( erryi ) tyin -= erryi / ( sigmax_tau * ( mu0y_in / tau_y + np . sum ( sumxy1 * muxy_in , 0 )) / tyin ) ty = tyin err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = mux0_in mu0y = mu0y_in muxy = muxy_in marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( muxy , mux0 , mu0y ), marg_err_x , marg_err_y else : # we compute the derivatives n_sum_categories = X + Y n_prod_categories = X * Y # we work directly with (mux0, mu0y) sigrat_xy = sumxy1 * sigma_x . reshape (( - 1 , 1 )) taurat_xy = 1.0 - sigrat_xy mux0_mat = nprepeat_col ( mux0 , Y ) mu0y_mat = nprepeat_row ( mu0y , X ) # muxy = axy * bxy * ephi2 axy = nppow ( mux0_mat , sigrat_xy ) bxy = nppow ( mu0y_mat , taurat_xy ) der_axy1 , der_axy2 = der_nppow ( mux0_mat , sigrat_xy ) der_bxy1 , der_bxy2 = der_nppow ( mu0y_mat , taurat_xy ) der_axy1_rat , der_axy2_rat = der_axy1 / axy , der_axy2 / axy der_bxy1_rat , der_bxy2_rat = der_bxy1 / bxy , der_bxy2 / bxy # start with the LHS of the linear system on (dmux0, dmu0y) lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 1.0 + np . sum ( muxy * der_axy1_rat , 1 )) lhs [: X , X :] = muxy * der_bxy1_rat lhs [ X :, X :] = np . diag ( 1.0 + np . sum ( muxy * der_bxy1_rat , 0 )) lhs [ X :, : X ] = ( muxy * der_axy1_rat ) . T # now fill the RHS (derivatives wrt men_margins, then men_margins, # then Phi, then sigma_x and tau_y) n_cols_rhs = n_sum_categories + n_prod_categories + X + Y rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (mux0, mu0y) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute derivatives of (mux0, mu0y) wrt women_margins rhs [ X :, X : n_sum_categories ] = np . eye ( Y ) # the next line is sumxy1 with safeguards sumxy1_safe = sumxy1 * der_ephi2 / ephi2 big_a = muxy * sumxy1_safe big_b = der_axy2_rat - der_bxy2_rat b_mu_s = big_b * muxy * sumxy1 a_phi = Phi * big_a big_c = sumxy1 * ( a_phi - b_mu_s * tau_y ) big_d = sumxy1 * ( a_phi + b_mu_s * sigma_x . reshape (( - 1 , 1 ))) # to compute derivatives of (mux0, mu0y) wrt Phi ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - big_a [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories iend_phi = n_sum_categories + n_prod_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : iend_phi : Y ] = - big_a [:, iwoman ] ivar1 += 1 ivar2 += 1 # to compute derivatives of (mux0, mu0y) wrt sigma_x iend_sig = iend_phi + X der_sigx = np . sum ( big_c , 1 ) rhs [: X , iend_phi : iend_sig ] = np . diag ( der_sigx ) rhs [ X :, iend_phi : iend_sig ] = big_c . T # to compute derivatives of (mux0, mu0y) wrt tau_y der_tauy = np . sum ( big_d , 0 ) rhs [ X :, iend_sig :] = np . diag ( der_tauy ) rhs [: X , iend_sig :] = big_d # solve for the derivatives of mux0 and mu0y dmu0 = spla . solve ( lhs , rhs ) dmux0 = dmu0 [: X , :] dmu0y = dmu0 [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) der1 = ephi2 * der_axy1 * bxy ivar = 0 for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), :] = np . outer ( der1 [ iman , :], dmux0 [ iman , :]) ivar += Y der2 = ephi2 * der_bxy1 * axy for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( der2 [:, iwoman ], dmu0y [ iwoman , :] ) # add the terms that comes from differentiating ephi2 # on the derivative wrt Phi i = 0 j = n_sum_categories for iman in range ( X ): for iwoman in range ( Y ): dmuxy [ i , j ] += big_a [ iman , iwoman ] i += 1 j += 1 # on the derivative wrt sigma_x ivar = 0 ix = iend_phi for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), ix ] -= big_c [ iman , :] ivar += Y ix += 1 # on the derivative wrt tau_y iy = iend_sig for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , iy ] -= big_d [:, iwoman ] iy += 1 return ( muxy , mux0 , mu0y ), marg_err_x , marg_err_y , ( dmuxy , dmux0 , dmu0y )","title":"ipfp_heteroskedastic_solver()"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_homoskedastic_nosingles_solver","text":"Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Parameters: Name Type Description Default Phi <built-in function array> matrix of systematic surplus, shape (X, Y) required men_margins <built-in function array> vector of men margins, shape (X) required women_margins <built-in function array> vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of $(\\mu_{xy})$ wrt $\\Phi$ False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy the matching patterns, shape (X, Y) marg_err_x, marg_err_y: the errors on the margins and the gradients of $(\\mu_{xy})$ wrt $\\Phi$ if gr is True Source code in cupid_matching/ipfp_solvers.py def ipfp_homoskedastic_nosingles_solver ( Phi : np . array , men_margins : np . array , women_margins : np . array , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPResults : \"\"\"Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of $(\\mu_{xy})$ wrt $\\Phi$ verbose: if `True`, prints information maxiter: maximum number of iterations Returns: muxy: the matching patterns, shape (X, Y) marg_err_x, marg_err_y: the errors on the margins and the gradients of $(\\mu_{xy})$ wrt $\\Phi$ if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) n_couples = np . sum ( men_margins ) # check that there are as many men as women if np . abs ( np . sum ( women_margins ) - n_couples ) > n_couples * tol : bs_error_abort ( \"There should be as many men as women\" ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = True ) ephi2T = ephi2 . T ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # starting with a reasonable initial point for tx and ty: : tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# bigc = sqrt ( n_couples / np . sum ( ephi2 )) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * err_diff niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = men_margins / sx sy = ephi2T @ tx ty = women_margins / sy err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi , tyi = tx , ty niter += 1 muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = np . sum ( muxy , 1 ) - men_margins marg_err_y = np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return muxy , marg_err_x , marg_err_y else : sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = 0 for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = 0 for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer (( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy += np . diag ( muxy_vec2 ) return muxy , marg_err_x , marg_err_y , dmuxy","title":"ipfp_homoskedastic_nosingles_solver()"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_homoskedastic_solver","text":"Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Parameters: Name Type Description Default Phi <built-in function array> matrix of systematic surplus, shape (X, Y) required men_margins <built-in function array> vector of men margins, shape (X) required women_margins <built-in function array> vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description (muxy, mux0, mu0y) the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) if gr is True Examples: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu , sigma = 0.0 , 1.0 n_bases = 4 bases_surplus = np . zeros (( X , Y , n_bases )) x_men = ( np . arange ( X ) - X / 2.0 ) / X y_women = ( np . arange ( Y ) - Y / 2.0 ) / Y bases_surplus [:, :, 0 ] = 1 for iy in range ( Y ): bases_surplus [:, iy , 1 ] = x_men for ix in range ( X ): bases_surplus [ ix , :, 2 ] = y_women for ix in range ( X ): for iy in range ( Y ): bases_surplus [ ix , iy , 3 ] = ( x_men [ ix ] - y_women [ iy ]) * ( x_men [ ix ] - y_women [ iy ] ) men_margins = np . random . uniform ( 1.0 , 10.0 , size = X ) women_margins = np . random . uniform ( 1.0 , 10.0 , size = Y ) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np . array ([ 3.0 , - 1.0 , - 1.0 , - 2.0 ]) true_surplus_matrix = bases_surplus @ true_surplus_params mus , marg_err_x , marg_err_y = ipfp_homoskedastic_solver ( true_surplus_matrix , men_margins , women_margins , tol = 1e-12 ) Source code in cupid_matching/ipfp_solvers.py def ipfp_homoskedastic_solver ( Phi : np . array , men_margins : np . array , women_margins : np . array , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPResults : \"\"\"Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) if `gr` is `True` Example: ```py # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu, sigma = 0.0, 1.0 n_bases = 4 bases_surplus = np.zeros((X, Y, n_bases)) x_men = (np.arange(X) - X / 2.0) / X y_women = (np.arange(Y) - Y / 2.0) / Y bases_surplus[:, :, 0] = 1 for iy in range(Y): bases_surplus[:, iy, 1] = x_men for ix in range(X): bases_surplus[ix, :, 2] = y_women for ix in range(X): for iy in range(Y): bases_surplus[ix, iy, 3] = (x_men[ix] - y_women[iy]) * ( x_men[ix] - y_women[iy] ) men_margins = np.random.uniform(1.0, 10.0, size=X) women_margins = np.random.uniform(1.0, 10.0, size=Y) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np.array([3.0, -1.0, -1.0, -2.0]) true_surplus_matrix = bases_surplus @ true_surplus_params mus, marg_err_x, marg_err_y = ipfp_homoskedastic_solver( true_surplus_matrix, men_margins, women_margins, tol=1e-12 ) ``` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = True ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # where mux0=tx**2 and mu0y=ty**2 # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# ephi2T = ephi2 . T nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = sqrt ( nindivs / ( X + Y + 2.0 * np . sum ( ephi2 ))) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * bigc niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = ( np . sqrt ( sx * sx + 4.0 * men_margins ) - sx ) / 2.0 sy = ephi2T @ tx ty = ( np . sqrt ( sy * sy + 4.0 * women_margins ) - sy ) / 2.0 err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = txi * txi mu0y = tyi * tyi muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( muxy , mux0 , mu0y ), marg_err_x , marg_err_y else : # we compute the derivatives sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 2.0 * txi + sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( 2.0 * tyi + syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_sum_categories + n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (txi, tyi) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute derivatives of (txi, tyi) wrt women_margins rhs [ X : n_sum_categories , X : n_sum_categories ] = np . eye ( Y ) # to compute derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of the mus dmux0 = 2.0 * ( dt * txi . reshape (( - 1 , 1 ))) dmu0y = 2.0 * ( dT * tyi . reshape (( - 1 , 1 ))) dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer (( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy [:, n_sum_categories :] += np . diag ( muxy_vec2 ) return ( muxy , mux0 , mu0y ), marg_err_x , marg_err_y , ( dmuxy , dmux0 , dmu0y )","title":"ipfp_homoskedastic_solver()"},{"location":"matching_utils/","text":"matching_utils module \u00b6 matching-related utilities Matching dataclass \u00b6 stores the numbers of couples and singles of every type; muxy is an (X,Y)-matrix n is an X-vector m is an Y-vector mux0 and mu0y are generated as the corresponding numbers of singles Source code in cupid_matching/matching_utils.py class Matching : \"\"\"stores the numbers of couples and singles of every type; muxy is an (X,Y)-matrix n is an X-vector m is an Y-vector mux0 and mu0y are generated as the corresponding numbers of singles \"\"\" mux0 : np . ndarray = field ( init = False ) mu0y : np . ndarray = field ( init = False ) muxy : np . ndarray n : np . ndarray m : np . ndarray def __str__ ( self ): X , Y = self . muxy . shape n_couples = np . sum ( self . muxy ) n_men , n_women = np . sum ( self . n ), np . sum ( self . m ) repr_str = f \"This is a matching with { n_men } men, { n_women } single women. \\n \" repr_str += f \" with { n_couples } couples, \\n \\n \" repr_str += f \" We have { X } types of men and { Y } of women.\" print_stars ( repr_str ) def __post_init__ ( self ): X , Y = test_matrix ( self . muxy ) Xn = test_vector ( self . n ) Ym = test_vector ( self . m ) if Xn != X : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) self . mux0 , self . mu0y = _get_singles ( self . muxy , self . n , self . m ) def unpack ( self ): return self . muxy , self . mux0 , self . mu0y , self . n , self . m","title":"matching_utils"},{"location":"matching_utils/#matching_utils-module","text":"matching-related utilities","title":"matching_utils module"},{"location":"matching_utils/#cupid_matching.matching_utils.Matching","text":"stores the numbers of couples and singles of every type; muxy is an (X,Y)-matrix n is an X-vector m is an Y-vector mux0 and mu0y are generated as the corresponding numbers of singles Source code in cupid_matching/matching_utils.py class Matching : \"\"\"stores the numbers of couples and singles of every type; muxy is an (X,Y)-matrix n is an X-vector m is an Y-vector mux0 and mu0y are generated as the corresponding numbers of singles \"\"\" mux0 : np . ndarray = field ( init = False ) mu0y : np . ndarray = field ( init = False ) muxy : np . ndarray n : np . ndarray m : np . ndarray def __str__ ( self ): X , Y = self . muxy . shape n_couples = np . sum ( self . muxy ) n_men , n_women = np . sum ( self . n ), np . sum ( self . m ) repr_str = f \"This is a matching with { n_men } men, { n_women } single women. \\n \" repr_str += f \" with { n_couples } couples, \\n \\n \" repr_str += f \" We have { X } types of men and { Y } of women.\" print_stars ( repr_str ) def __post_init__ ( self ): X , Y = test_matrix ( self . muxy ) Xn = test_vector ( self . n ) Ym = test_vector ( self . m ) if Xn != X : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) self . mux0 , self . mu0y = _get_singles ( self . muxy , self . n , self . m ) def unpack ( self ): return self . muxy , self . mux0 , self . mu0y , self . n , self . m","title":"Matching"},{"location":"min_distance/","text":"min_distance module \u00b6 Estimates semilinear separable models with a given entropy function. The entropy function and the surplus matrix must both be linear in the parameters. estimate_semilinear_mde ( muhat , phi_bases , entropy , more_params = None , initial_weights = None ) \u00b6 Estimates the parameters of the distributions and of the base functions. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases ndarray an (X, Y, K) array of bases required entropy EntropyFunctions an EntropyFunctions object required more_params Optional[List] additional parameters of the distribution of errors, if any None initial_weights Optional[numpy.ndarray] if specified, used as the weighting matrix for the first step when entropy.param_dependent is True None Returns: Type Description MDEResults an MDEResults instance Examples: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 X , Y , K = 10 , 20 , 2 n_households = int ( 1e6 ) # we simulate a Choo and Siow population # with equal numbers of men and women of each type lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) choo_siow_instance . describe () muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np . ones ( n_alpha ) true_coeffs = np . concatenate (( true_alpha , lambda_true )) print_stars ( entropy_model . description ) mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy_model , more_params = more_params ) mde_results . print_results ( true_coeffs = true_coeffs , n_alpha = 1 ) Source code in cupid_matching/min_distance.py def estimate_semilinear_mde ( muhat : Matching , phi_bases : np . ndarray , entropy : EntropyFunctions , more_params : Optional [ List ] = None , initial_weights : Optional [ np . ndarray ] = None , ) -> MDEResults : \"\"\" Estimates the parameters of the distributions and of the base functions. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases entropy: an `EntropyFunctions` object more_params: additional parameters of the distribution of errors, if any initial_weights: if specified, used as the weighting matrix for the first step when `entropy.param_dependent` is `True` Returns: an `MDEResults` instance Example: ```py X, Y, K = 10, 20, 2 n_households = int(1e6) # we simulate a Choo and Siow population # with equal numbers of men and women of each type lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) n = np.ones(X) m = np.ones(Y) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) choo_siow_instance.describe() muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack() entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np.ones(n_alpha) true_coeffs = np.concatenate((true_alpha, lambda_true)) print_stars(entropy_model.description) mde_results = estimate_semilinear_mde( mus_sim, phi_bases, entropy_model, more_params=more_params ) mde_results.print_results(true_coeffs=true_coeffs, n_alpha=1) ``` \"\"\" muxyhat , _ , _ , nhat , mhat = muhat . unpack () X , Y = muxyhat . shape XY = X * Y ndims_phi = phi_bases . ndim if ndims_phi != 3 : bs_error_abort ( f \"phi_bases should have 3 dimensions, not { ndims_phi } \" ) Xp , Yp , K = phi_bases . shape if Xp != X or Yp != Y : bs_error_abort ( f \"phi_bases should have shape ( { X } , { Y } , { K } ) not ( { Xp } , { Yp } , { K } )\" ) parameterized_entropy = entropy . parameter_dependent if parameterized_entropy : if initial_weights is None : print_stars ( \"Using the identity matrix as weighting matrix in the first step.\" ) S_mat = np . eye ( XY ) else : S_mat = initial_weights phi_mat = _make_XY_K_mat ( phi_bases ) e0_fun = entropy . e0_fun if more_params is None : e0_vals = e0_fun ( muhat ) else : e0_vals = e0_fun ( muhat , more_params ) e0_hat = e0_vals . ravel () if not parameterized_entropy : # we only have e0(mu,r) n_pars = K hessian = entropy . hessian if hessian == \"provided\" : e0_derivative = entropy . e0_derivative if more_params is None : hessian_components = e0_derivative ( muhat ) else : hessian_components = e0_derivative ( muhat , more_params ) else : if more_params is None : hessian_components = _numeric_hessian ( entropy , muhat ) else : hessian_components = _numeric_hessian ( entropy , muhat , more_params ) hessian_components_mumu , hessian_components_mur = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) _ , var_munm = _variance_muhat ( muhat ) var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) estimated_coefficients , varcov_coefficients = _compute_estimates ( phi_mat , S_mat , e0_hat ) stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ estimated_coefficients residuals = est_Phi + e0_hat else : # parameterized entropy: e0(mu,r) + e(mu,r) . alpha # create the F matrix e_fun = entropy . e_fun if more_params is None : e_vals = e_fun ( muhat ) else : e_vals = e_fun ( muhat , more_params ) e_hat = _make_XY_K_mat ( e_vals ) F_hat = np . column_stack (( e_hat , phi_mat )) n_pars = e_hat . shape [ 1 ] + K # first pass with an initial weighting matrix first_coeffs , _ = _compute_estimates ( F_hat , S_mat , e0_hat ) first_alpha = first_coeffs [: - K ] # compute the efficient weighting matrix hessian = entropy . hessian if hessian == \"provided\" : e0_derivative = entropy . e0_derivative e_derivative = entropy . e_derivative if more_params is None : hessian_components_e0 = e0_derivative ( muhat ) hessian_components_e = e_derivative ( muhat ) else : hessian_components_e0 = e0_derivative ( muhat , more_params ) hessian_components_e = e_derivative ( muhat , more_params ) # print_stars(\"First-stage estimates:\") # print(first_coeffs) ( hessian_components_mumu_e0 , hessian_components_mur_e0 , ) = hessian_components_e0 hessian_components_mumu_e , hessian_components_mur_e = hessian_components_e hessian_components_mumu = [] for c in [ 0 , 1 , 2 ]: hessian_components_mumu . append ( hessian_components_mumu_e0 [ c ] + hessian_components_mumu_e [ c ] @ first_alpha ) hessian_components_mur = [] for c in [ 0 , 1 ]: hessian_components_mur . append ( hessian_components_mur_e0 [ c ] + hessian_components_mur_e [ c ] @ first_alpha ) else : if more_params is None : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha ) else : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha , more_params = more_params ) hessian_components_mumu , hessian_components_mur = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) _ , var_munm = _variance_muhat ( muhat ) var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) # second pass estimated_coefficients , varcov_coefficients = _compute_estimates ( F_hat , S_mat , e0_hat ) est_alpha , est_beta = estimated_coefficients [: - K ], estimated_coefficients [ - K :] stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ est_beta residuals = est_Phi + e0_hat + e_hat @ est_alpha value_obj = residuals . T @ S_mat @ residuals ndf = X * Y - n_pars test_stat = value_obj n_households = np . sum ( nhat ) + np . sum ( mhat ) - np . sum ( muxyhat ) results = MDEResults ( X = X , Y = Y , K = K , number_households = n_households , estimated_coefficients = estimated_coefficients , varcov_coefficients = varcov_coefficients , stderrs_coefficients = stderrs_coefficients , estimated_Phi = est_Phi . reshape (( X , Y )), test_statistic = test_stat , ndf = ndf , test_pvalue = sts . chi2 . sf ( test_stat , ndf ), parameterized_entropy = parameterized_entropy , ) return results","title":"min_distance"},{"location":"min_distance/#min_distance-module","text":"Estimates semilinear separable models with a given entropy function. The entropy function and the surplus matrix must both be linear in the parameters.","title":"min_distance module"},{"location":"min_distance/#cupid_matching.min_distance.estimate_semilinear_mde","text":"Estimates the parameters of the distributions and of the base functions. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases ndarray an (X, Y, K) array of bases required entropy EntropyFunctions an EntropyFunctions object required more_params Optional[List] additional parameters of the distribution of errors, if any None initial_weights Optional[numpy.ndarray] if specified, used as the weighting matrix for the first step when entropy.param_dependent is True None Returns: Type Description MDEResults an MDEResults instance Examples: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 X , Y , K = 10 , 20 , 2 n_households = int ( 1e6 ) # we simulate a Choo and Siow population # with equal numbers of men and women of each type lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) choo_siow_instance . describe () muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np . ones ( n_alpha ) true_coeffs = np . concatenate (( true_alpha , lambda_true )) print_stars ( entropy_model . description ) mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy_model , more_params = more_params ) mde_results . print_results ( true_coeffs = true_coeffs , n_alpha = 1 ) Source code in cupid_matching/min_distance.py def estimate_semilinear_mde ( muhat : Matching , phi_bases : np . ndarray , entropy : EntropyFunctions , more_params : Optional [ List ] = None , initial_weights : Optional [ np . ndarray ] = None , ) -> MDEResults : \"\"\" Estimates the parameters of the distributions and of the base functions. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases entropy: an `EntropyFunctions` object more_params: additional parameters of the distribution of errors, if any initial_weights: if specified, used as the weighting matrix for the first step when `entropy.param_dependent` is `True` Returns: an `MDEResults` instance Example: ```py X, Y, K = 10, 20, 2 n_households = int(1e6) # we simulate a Choo and Siow population # with equal numbers of men and women of each type lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) n = np.ones(X) m = np.ones(Y) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) choo_siow_instance.describe() muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack() entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np.ones(n_alpha) true_coeffs = np.concatenate((true_alpha, lambda_true)) print_stars(entropy_model.description) mde_results = estimate_semilinear_mde( mus_sim, phi_bases, entropy_model, more_params=more_params ) mde_results.print_results(true_coeffs=true_coeffs, n_alpha=1) ``` \"\"\" muxyhat , _ , _ , nhat , mhat = muhat . unpack () X , Y = muxyhat . shape XY = X * Y ndims_phi = phi_bases . ndim if ndims_phi != 3 : bs_error_abort ( f \"phi_bases should have 3 dimensions, not { ndims_phi } \" ) Xp , Yp , K = phi_bases . shape if Xp != X or Yp != Y : bs_error_abort ( f \"phi_bases should have shape ( { X } , { Y } , { K } ) not ( { Xp } , { Yp } , { K } )\" ) parameterized_entropy = entropy . parameter_dependent if parameterized_entropy : if initial_weights is None : print_stars ( \"Using the identity matrix as weighting matrix in the first step.\" ) S_mat = np . eye ( XY ) else : S_mat = initial_weights phi_mat = _make_XY_K_mat ( phi_bases ) e0_fun = entropy . e0_fun if more_params is None : e0_vals = e0_fun ( muhat ) else : e0_vals = e0_fun ( muhat , more_params ) e0_hat = e0_vals . ravel () if not parameterized_entropy : # we only have e0(mu,r) n_pars = K hessian = entropy . hessian if hessian == \"provided\" : e0_derivative = entropy . e0_derivative if more_params is None : hessian_components = e0_derivative ( muhat ) else : hessian_components = e0_derivative ( muhat , more_params ) else : if more_params is None : hessian_components = _numeric_hessian ( entropy , muhat ) else : hessian_components = _numeric_hessian ( entropy , muhat , more_params ) hessian_components_mumu , hessian_components_mur = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) _ , var_munm = _variance_muhat ( muhat ) var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) estimated_coefficients , varcov_coefficients = _compute_estimates ( phi_mat , S_mat , e0_hat ) stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ estimated_coefficients residuals = est_Phi + e0_hat else : # parameterized entropy: e0(mu,r) + e(mu,r) . alpha # create the F matrix e_fun = entropy . e_fun if more_params is None : e_vals = e_fun ( muhat ) else : e_vals = e_fun ( muhat , more_params ) e_hat = _make_XY_K_mat ( e_vals ) F_hat = np . column_stack (( e_hat , phi_mat )) n_pars = e_hat . shape [ 1 ] + K # first pass with an initial weighting matrix first_coeffs , _ = _compute_estimates ( F_hat , S_mat , e0_hat ) first_alpha = first_coeffs [: - K ] # compute the efficient weighting matrix hessian = entropy . hessian if hessian == \"provided\" : e0_derivative = entropy . e0_derivative e_derivative = entropy . e_derivative if more_params is None : hessian_components_e0 = e0_derivative ( muhat ) hessian_components_e = e_derivative ( muhat ) else : hessian_components_e0 = e0_derivative ( muhat , more_params ) hessian_components_e = e_derivative ( muhat , more_params ) # print_stars(\"First-stage estimates:\") # print(first_coeffs) ( hessian_components_mumu_e0 , hessian_components_mur_e0 , ) = hessian_components_e0 hessian_components_mumu_e , hessian_components_mur_e = hessian_components_e hessian_components_mumu = [] for c in [ 0 , 1 , 2 ]: hessian_components_mumu . append ( hessian_components_mumu_e0 [ c ] + hessian_components_mumu_e [ c ] @ first_alpha ) hessian_components_mur = [] for c in [ 0 , 1 ]: hessian_components_mur . append ( hessian_components_mur_e0 [ c ] + hessian_components_mur_e [ c ] @ first_alpha ) else : if more_params is None : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha ) else : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha , more_params = more_params ) hessian_components_mumu , hessian_components_mur = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) _ , var_munm = _variance_muhat ( muhat ) var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) # second pass estimated_coefficients , varcov_coefficients = _compute_estimates ( F_hat , S_mat , e0_hat ) est_alpha , est_beta = estimated_coefficients [: - K ], estimated_coefficients [ - K :] stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ est_beta residuals = est_Phi + e0_hat + e_hat @ est_alpha value_obj = residuals . T @ S_mat @ residuals ndf = X * Y - n_pars test_stat = value_obj n_households = np . sum ( nhat ) + np . sum ( mhat ) - np . sum ( muxyhat ) results = MDEResults ( X = X , Y = Y , K = K , number_households = n_households , estimated_coefficients = estimated_coefficients , varcov_coefficients = varcov_coefficients , stderrs_coefficients = stderrs_coefficients , estimated_Phi = est_Phi . reshape (( X , Y )), test_statistic = test_stat , ndf = ndf , test_pvalue = sts . chi2 . sf ( test_stat , ndf ), parameterized_entropy = parameterized_entropy , ) return results","title":"estimate_semilinear_mde()"},{"location":"min_distance_utils/","text":"min_distance_utils module \u00b6 Utility programs used in min_distance.py . MDEResults dataclass \u00b6 The results from minimum-distance estimation and testing. Parameters: Name Type Description Default X int int required Y int int required K int int required number_households int int required estimated_coefficients ndarray np.ndarray required varcov_coefficients ndarray np.ndarray required stderrs_coefficients ndarray np.ndarray required estimated_Phi ndarray np.ndarray required test_statistic float float required test_pvalue float float required ndf int int required parameterized_entropy Optional[bool] Optional[bool] = False False Source code in cupid_matching/min_distance_utils.py class MDEResults : \"\"\" The results from minimum-distance estimation and testing. Args: X: int Y: int K: int number_households: int estimated_coefficients: np.ndarray varcov_coefficients: np.ndarray stderrs_coefficients: np.ndarray estimated_Phi: np.ndarray test_statistic: float test_pvalue: float ndf: int parameterized_entropy: Optional[bool] = False \"\"\" X : int Y : int K : int number_households : int estimated_coefficients : np . ndarray varcov_coefficients : np . ndarray stderrs_coefficients : np . ndarray estimated_Phi : np . ndarray test_statistic : float test_pvalue : float ndf : int parameterized_entropy : Optional [ bool ] = False def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" if self . parameterized_entropy : n_alpha = self . estimated_coefficients . size - self . K entropy_str = f \" The entropy has { n_alpha } parameters.\" else : entropy_str = \" The entropy is parameter-free.\" n_alpha = 0 model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += f \"The model has { self . X } x { self . Y } margins \\n { entropy_str } \\n \" model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += \"The estimated coefficients (and their standard errors) are \\n\\n \" if self . parameterized_entropy : for i , coeff in enumerate ( self . estimated_coefficients [: n_alpha ]): repr_str += ( f \" alpha( { i + 1 } ): { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ i ] : .3f } ) \\n \" ) repr_str += \" \\n \" for i , coeff in enumerate ( self . estimated_coefficients [ n_alpha :]): repr_str += ( f \" base { i + 1 } : { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ n_alpha + i ] : .3f } ) \\n \" ) repr_str += \" \\n Specification test: \\n \" repr_str += ( f \" the value of the test statistic is { self . test_statistic : > 10.3f } \\n \" ) repr_str += ( f \" for a chi2( { self . ndf } ), the p-value is { self . test_pvalue : > 10.3f } \\n \" ) return repr_str + line_stars def print_results ( self , true_coeffs : Optional [ np . ndarray ] = None , n_alpha : int = 0 ) -> Union [ None , float ]: estimates = self . estimated_coefficients stderrs = self . stderrs_coefficients repr_str = ( \"The true and estimated coefficients \" + \"(and their standard errors) are \\n\\n \" ) for i , coeff in enumerate ( estimates [: n_alpha ]): repr_str += f \" alpha( { i + 1 } ): { true_coeffs [ i ] : > 10.3f } \" repr_str + f \" { coeff : > 10.3f } ( { stderrs [ i ] : > 10.3f } ) \\n \" repr_str += \" \\n \" for i , coeff in enumerate ( estimates [ n_alpha :]): j = n_alpha + i repr_str += ( f \" base { i + 1 } : { true_coeffs [ j ] : > 10.3f } \" + f \" { coeff : > 10.3f } ( { stderrs [ j ] : > 10.3f } ) \\n \" ) repr_str += \" \\n Specification test: \\n \" repr_str += ( \" the value of the test statistic is \" + f \" { self . test_statistic : > 10.3f } \\n \" ) repr_str += ( f \" for a chi2( { self . ndf } ), \" + f \"the p-value is { self . test_pvalue : > 10.3f } \\n \" ) print_stars ( repr_str ) if true_coeffs is not None : discrepancy = npmaxabs ( true_coeffs - estimates ) print_stars ( f \"The true-estimated discrepancy is { discrepancy } \" ) return discrepancy","title":"min_distance_utils"},{"location":"min_distance_utils/#min_distance_utils-module","text":"Utility programs used in min_distance.py .","title":"min_distance_utils module"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.MDEResults","text":"The results from minimum-distance estimation and testing. Parameters: Name Type Description Default X int int required Y int int required K int int required number_households int int required estimated_coefficients ndarray np.ndarray required varcov_coefficients ndarray np.ndarray required stderrs_coefficients ndarray np.ndarray required estimated_Phi ndarray np.ndarray required test_statistic float float required test_pvalue float float required ndf int int required parameterized_entropy Optional[bool] Optional[bool] = False False Source code in cupid_matching/min_distance_utils.py class MDEResults : \"\"\" The results from minimum-distance estimation and testing. Args: X: int Y: int K: int number_households: int estimated_coefficients: np.ndarray varcov_coefficients: np.ndarray stderrs_coefficients: np.ndarray estimated_Phi: np.ndarray test_statistic: float test_pvalue: float ndf: int parameterized_entropy: Optional[bool] = False \"\"\" X : int Y : int K : int number_households : int estimated_coefficients : np . ndarray varcov_coefficients : np . ndarray stderrs_coefficients : np . ndarray estimated_Phi : np . ndarray test_statistic : float test_pvalue : float ndf : int parameterized_entropy : Optional [ bool ] = False def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" if self . parameterized_entropy : n_alpha = self . estimated_coefficients . size - self . K entropy_str = f \" The entropy has { n_alpha } parameters.\" else : entropy_str = \" The entropy is parameter-free.\" n_alpha = 0 model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += f \"The model has { self . X } x { self . Y } margins \\n { entropy_str } \\n \" model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += \"The estimated coefficients (and their standard errors) are \\n\\n \" if self . parameterized_entropy : for i , coeff in enumerate ( self . estimated_coefficients [: n_alpha ]): repr_str += ( f \" alpha( { i + 1 } ): { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ i ] : .3f } ) \\n \" ) repr_str += \" \\n \" for i , coeff in enumerate ( self . estimated_coefficients [ n_alpha :]): repr_str += ( f \" base { i + 1 } : { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ n_alpha + i ] : .3f } ) \\n \" ) repr_str += \" \\n Specification test: \\n \" repr_str += ( f \" the value of the test statistic is { self . test_statistic : > 10.3f } \\n \" ) repr_str += ( f \" for a chi2( { self . ndf } ), the p-value is { self . test_pvalue : > 10.3f } \\n \" ) return repr_str + line_stars def print_results ( self , true_coeffs : Optional [ np . ndarray ] = None , n_alpha : int = 0 ) -> Union [ None , float ]: estimates = self . estimated_coefficients stderrs = self . stderrs_coefficients repr_str = ( \"The true and estimated coefficients \" + \"(and their standard errors) are \\n\\n \" ) for i , coeff in enumerate ( estimates [: n_alpha ]): repr_str += f \" alpha( { i + 1 } ): { true_coeffs [ i ] : > 10.3f } \" repr_str + f \" { coeff : > 10.3f } ( { stderrs [ i ] : > 10.3f } ) \\n \" repr_str += \" \\n \" for i , coeff in enumerate ( estimates [ n_alpha :]): j = n_alpha + i repr_str += ( f \" base { i + 1 } : { true_coeffs [ j ] : > 10.3f } \" + f \" { coeff : > 10.3f } ( { stderrs [ j ] : > 10.3f } ) \\n \" ) repr_str += \" \\n Specification test: \\n \" repr_str += ( \" the value of the test statistic is \" + f \" { self . test_statistic : > 10.3f } \\n \" ) repr_str += ( f \" for a chi2( { self . ndf } ), \" + f \"the p-value is { self . test_pvalue : > 10.3f } \\n \" ) print_stars ( repr_str ) if true_coeffs is not None : discrepancy = npmaxabs ( true_coeffs - estimates ) print_stars ( f \"The true-estimated discrepancy is { discrepancy } \" ) return discrepancy","title":"MDEResults"},{"location":"nested_logit/","text":"nested_logit module \u00b6 The components of the derivative of the entropy for a two-layer nested logit model. One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters. e0_derivative_nested_logit ( muhat , more_params ) \u00b6 Returns the derivatives of the parameter-independent part $e_0$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required more_params List a list with the nest structure required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-independent part of the hessian of the entropy. Source code in cupid_matching/nested_logit.py def e0_derivative_nested_logit ( muhat : Matching , more_params : List ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ for the nested logit. Args: muhat: a Matching more_params: a list with the nest structure Returns: the components of the parameter-independent part of the hessian of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = more_params nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y for x in range ( X ): dlogx0 = der_logx0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) der_logxn = 1.0 / mu_xn for y in nest : hess_x [ x , y , :] = - dlogx0 hess_x [ x , y , nest ] -= der_logxn hess_n [ x , y ] = dlogx0 for y in range ( Y ): dlog0y = der_log0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) der_logny = 1.0 / mu_ny for x in nest : hess_y [ x , y , :] = - dlog0y hess_y [ x , y , nest ] -= der_logny hess_m [ x , y ] = dlog0y for x in range ( X ): for y in range ( Y ): hess_xy [ x , y ] = hess_x [ x , y , y ] + hess_y [ x , y , x ] return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m ) e0_nested_logit ( muhat , more_params ) \u00b6 Returns the values of the parameter-independent part $e_0$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required more_params List a list with the nest structure required Returns: Type Description ndarray the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. Source code in cupid_matching/nested_logit.py def e0_nested_logit ( muhat : Matching , more_params : List ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the nested logit. Args: muhat: a Matching more_params: a list with the nest structure Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = more_params nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape e0_vals = np . zeros (( X , Y )) for x in range ( X ): mux0_x = mux0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) e0_vals [ x , nest ] = - log ( mu_xn / mux0_x ) for y in range ( Y ): mu0y_y = mu0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) e0_vals [ nest , y ] -= log ( mu_ny / mu0y_y ) return e0_vals e_derivative_nested_logit ( muhat , more_params ) \u00b6 Returns the derivatives of the parameter-dependent part $e$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required more_params List a list with the nest structure required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-dependent part of the hessian of the entropy. Source code in cupid_matching/nested_logit.py def e_derivative_nested_logit ( muhat : Matching , more_params : List ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-dependent part $e$ for the nested logit. Args: muhat: a Matching more_params: a list with the nest structure Returns: the components of the parameter-dependent part of the hessian of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = more_params nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) der_logxn = 1.0 / mu_xn for t in nest : hess_x [ x , nest , t , i_n ] = der_logxn hess_xy [ x , nest , i_n ] = der_logxn - der_logxy [ x , nest ] for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) der_logny = 1.0 / mu_ny i_n2 = i_n + n_rhos for z in nest : hess_y [ nest , y , z , i_n2 ] = der_logny hess_xy [ nest , y , i_n2 ] = der_logny - der_logxy [ nest , y ] return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m ) e_nested_logit ( muhat , more_params ) \u00b6 Returns the values of the parameter-dependent part $e$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required more_params List a list with the nest structure required Returns: Type Description ndarray the (X,Y,n_alpha) array of the parameter-dependent part of the first derivative of the entropy. Source code in cupid_matching/nested_logit.py def e_nested_logit ( muhat : Matching , more_params : List ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the nested logit. Args: muhat: a Matching more_params: a list with the nest structure Returns: the (X,Y,n_alpha) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = more_params nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape e_vals = np . zeros (( X , Y , n_alpha )) for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) e_vals [ x , nest , i_n ] = - np . log ( mux_nest_n / mu_xn ) for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) e_vals [ nest , y , ( i_n + n_rhos )] -= np . log ( muy_nest_n / mu_ny ) return e_vals","title":"nested_logit"},{"location":"nested_logit/#nested_logit-module","text":"The components of the derivative of the entropy for a two-layer nested logit model. One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters.","title":"nested_logit module"},{"location":"nested_logit/#cupid_matching.nested_logit.e0_derivative_nested_logit","text":"Returns the derivatives of the parameter-independent part $e_0$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required more_params List a list with the nest structure required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-independent part of the hessian of the entropy. Source code in cupid_matching/nested_logit.py def e0_derivative_nested_logit ( muhat : Matching , more_params : List ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ for the nested logit. Args: muhat: a Matching more_params: a list with the nest structure Returns: the components of the parameter-independent part of the hessian of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = more_params nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y for x in range ( X ): dlogx0 = der_logx0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) der_logxn = 1.0 / mu_xn for y in nest : hess_x [ x , y , :] = - dlogx0 hess_x [ x , y , nest ] -= der_logxn hess_n [ x , y ] = dlogx0 for y in range ( Y ): dlog0y = der_log0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) der_logny = 1.0 / mu_ny for x in nest : hess_y [ x , y , :] = - dlog0y hess_y [ x , y , nest ] -= der_logny hess_m [ x , y ] = dlog0y for x in range ( X ): for y in range ( Y ): hess_xy [ x , y ] = hess_x [ x , y , y ] + hess_y [ x , y , x ] return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m )","title":"e0_derivative_nested_logit()"},{"location":"nested_logit/#cupid_matching.nested_logit.e0_nested_logit","text":"Returns the values of the parameter-independent part $e_0$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required more_params List a list with the nest structure required Returns: Type Description ndarray the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. Source code in cupid_matching/nested_logit.py def e0_nested_logit ( muhat : Matching , more_params : List ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the nested logit. Args: muhat: a Matching more_params: a list with the nest structure Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = more_params nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape e0_vals = np . zeros (( X , Y )) for x in range ( X ): mux0_x = mux0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) e0_vals [ x , nest ] = - log ( mu_xn / mux0_x ) for y in range ( Y ): mu0y_y = mu0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) e0_vals [ nest , y ] -= log ( mu_ny / mu0y_y ) return e0_vals","title":"e0_nested_logit()"},{"location":"nested_logit/#cupid_matching.nested_logit.e_derivative_nested_logit","text":"Returns the derivatives of the parameter-dependent part $e$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required more_params List a list with the nest structure required Returns: Type Description Tuple[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]] the components of the parameter-dependent part of the hessian of the entropy. Source code in cupid_matching/nested_logit.py def e_derivative_nested_logit ( muhat : Matching , more_params : List ) -> EntropyHessianComponents : \"\"\"Returns the derivatives of the parameter-dependent part $e$ for the nested logit. Args: muhat: a Matching more_params: a list with the nest structure Returns: the components of the parameter-dependent part of the hessian of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = more_params nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) der_logxn = 1.0 / mu_xn for t in nest : hess_x [ x , nest , t , i_n ] = der_logxn hess_xy [ x , nest , i_n ] = der_logxn - der_logxy [ x , nest ] for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) der_logny = 1.0 / mu_ny i_n2 = i_n + n_rhos for z in nest : hess_y [ nest , y , z , i_n2 ] = der_logny hess_xy [ nest , y , i_n2 ] = der_logny - der_logxy [ nest , y ] return ( hess_x , hess_y , hess_xy ), ( hess_n , hess_m )","title":"e_derivative_nested_logit()"},{"location":"nested_logit/#cupid_matching.nested_logit.e_nested_logit","text":"Returns the values of the parameter-dependent part $e$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required more_params List a list with the nest structure required Returns: Type Description ndarray the (X,Y,n_alpha) array of the parameter-dependent part of the first derivative of the entropy. Source code in cupid_matching/nested_logit.py def e_nested_logit ( muhat : Matching , more_params : List ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the nested logit. Args: muhat: a Matching more_params: a list with the nest structure Returns: the (X,Y,n_alpha) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = more_params nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape e_vals = np . zeros (( X , Y , n_alpha )) for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) e_vals [ x , nest , i_n ] = - np . log ( mux_nest_n / mu_xn ) for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) e_vals [ nest , y , ( i_n + n_rhos )] -= np . log ( muy_nest_n / mu_ny ) return e_vals","title":"e_nested_logit()"},{"location":"poisson_glm/","text":"poisson_glm module \u00b6 Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. choo_siow_poisson_glm ( muhat , phi_bases , tol = 1e-12 , max_iter = 10000 , verbose = 1 ) \u00b6 Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases ndarray an (X, Y, K) array of bases required tol Optional[float] tolerance level for linear_model.PoissonRegressor.fit 1e-12 max_iter Optional[int] maximum number of iterations for linear_model.PoissonRegressor.fit 10000 verbose Optional[int] defines how much output we want (0 = least) 1 Returns: Type Description PoissonGLMResults a PoissonGLMResults instance Examples: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 n_households = 1e6 X , Y , K = 4 , 3 , 6 # we setup a quadratic set of basis functions phi_bases = np . zeros (( X , Y , K )) phi_bases [:, :, 0 ] = 1 for x in range ( X ): phi_bases [ x , :, 1 ] = x phi_bases [ x , :, 3 ] = x * x for y in range ( Y ): phi_bases [ x , y , 4 ] = x * y for y in range ( Y ): phi_bases [:, y , 2 ] = y phi_bases [:, y , 5 ] = y * y lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np . ones ( X ) m = np . ones ( Y ) choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () results = choo_siow_poisson_glm ( mus_sim , phi_bases ) # compare true and estimated parameters results . print_results ( lambda_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ) ) Source code in cupid_matching/poisson_glm.py def choo_siow_poisson_glm ( muhat : Matching , phi_bases : np . ndarray , tol : Optional [ float ] = 1e-12 , max_iter : Optional [ int ] = 10000 , verbose : Optional [ int ] = 1 , ) -> PoissonGLMResults : \"\"\"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases tol: tolerance level for `linear_model.PoissonRegressor.fit` max_iter: maximum number of iterations for `linear_model.PoissonRegressor.fit` verbose: defines how much output we want (0 = least) Returns: a `PoissonGLMResults` instance Example: ```py n_households = 1e6 X, Y, K = 4, 3, 6 # we setup a quadratic set of basis functions phi_bases = np.zeros((X, Y, K)) phi_bases[:, :, 0] = 1 for x in range(X): phi_bases[x, :, 1] = x phi_bases[x, :, 3] = x * x for y in range(Y): phi_bases[x, y, 4] = x * y for y in range(Y): phi_bases[:, y, 2] = y phi_bases[:, y, 5] = y * y lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np.ones(X) m = np.ones(Y) choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack() results = choo_siow_poisson_glm(mus_sim, phi_bases) # compare true and estimated parameters results.print_results( lambda_true, u_true=-np.log(mux0_sim / n_sim), v_true=-np.log(mu0y_sim / m_sim) ) ``` \"\"\" try_sparse = False X , Y , K = phi_bases . shape XY = X * Y n_rows = XY + X + Y n_cols = X + Y + K # the vector of weights for the Poisson regression w = np . concatenate (( 2 * np . ones ( XY ), np . ones ( X + Y ))) # reshape the bases phi_mat = _make_XY_K_mat ( phi_bases ) if try_sparse : w_mat = spr . csr_matrix ( np . concatenate (( 2 * np . ones ( XY , n_cols ), np . ones ( X + Y , n_cols ))) ) # construct the Z matrix ones_X = spr . csr_matrix ( np . ones (( X , 1 ))) ones_Y = spr . csr_matrix ( np . ones (( Y , 1 ))) zeros_XK = spr . csr_matrix ( np . zeros (( X , K ))) zeros_YK = spr . csr_matrix ( np . zeros (( Y , K ))) zeros_XY = spr . csr_matrix ( np . zeros (( X , Y ))) zeros_YX = spr . csr_matrix ( np . zeros (( Y , X ))) id_X = spr . csr_matrix ( np . eye ( X )) id_Y = spr . csr_matrix ( np . eye ( Y )) Z_unweighted = spr . vstack ( [ spr . hstack ([ - spr . kron ( id_X , ones_Y ), - spr . kron ( ones_X , id_Y ), phi_mat ]), spr . hstack ([ - id_X , zeros_XY , zeros_XK ]), spr . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w_mat else : ones_X = np . ones (( X , 1 )) ones_Y = np . ones (( Y , 1 )) zeros_XK = np . zeros (( X , K )) zeros_YK = np . zeros (( Y , K )) zeros_XY = np . zeros (( X , Y )) zeros_YX = np . zeros (( Y , X )) id_X = np . eye ( X ) id_Y = np . eye ( Y ) Z_unweighted = np . vstack ( [ np . hstack ([ - np . kron ( id_X , ones_Y ), - np . kron ( ones_X , id_Y ), phi_mat ]), np . hstack ([ - id_X , zeros_XY , zeros_XK ]), np . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w . reshape (( - 1 , 1 )) _ , _ , _ , n , m = muhat . unpack () var_muhat , var_munm = _variance_muhat ( muhat ) ( muxyhat_norm , var_muhat_norm , var_munm_norm , n_households , n_individuals , ) = _prepare_data ( muhat , var_muhat , var_munm ) clf = linear_model . PoissonRegressor ( fit_intercept = False , tol = tol , verbose = verbose , alpha = 0 , max_iter = max_iter ) clf . fit ( Z , muxyhat_norm , sample_weight = w ) gamma_est = clf . coef_ # we compute the variance-covariance of the estimator nr , nc = Z . shape exp_Zg = np . exp ( Z @ gamma_est ) . reshape ( n_rows ) A_hat = np . zeros (( nc , nc )) B_hat = np . zeros (( nc , nc )) for i in range ( nr ): Zi = Z [ i , :] wi = w [ i ] A_hat += wi * exp_Zg [ i ] * np . outer ( Zi , Zi ) for j in range ( nr ): Zj = Z [ j , :] B_hat += wi * w [ j ] * var_muhat_norm [ i , j ] * np . outer ( Zi , Zj ) A_inv = spla . inv ( A_hat ) variance_gamma = A_inv @ B_hat @ A_inv stderrs_gamma = np . sqrt ( np . diag ( variance_gamma )) beta_est = gamma_est [ - K :] beta_std = stderrs_gamma [ - K :] Phi_est = phi_bases @ beta_est # we correct for the effect of the normalization n_norm = n / n_individuals m_norm = m / n_individuals u_est = gamma_est [: X ] + np . log ( n_norm ) v_est = gamma_est [ X : - K ] + np . log ( m_norm ) # since u = a + log(n_norm) we also need to adjust the estimated variance z_unweighted_T = Z_unweighted . T u_std = np . zeros ( X ) ix = XY for x in range ( X ): n_norm_x = n_norm [ x ] A_inv_x = A_inv [ x , :] var_log_nx = var_munm_norm [ ix , ix ] / n_norm_x / n_norm_x slice_x = slice ( x * Y , ( x + 1 ) * Y ) covar_term = var_muhat_norm [:, ix ] + np . sum ( var_muhat_norm [:, slice_x ], 1 ) cov_a_lognx = ( A_inv_x @ z_unweighted_T @ covar_term ) / n_norm_x ux_var = variance_gamma [ x , x ] + var_log_nx + 2.0 * cov_a_lognx u_std [ x ] = sqrt ( ux_var ) ix += 1 v_std = stderrs_gamma [ X : - K ] iy , jy = X , XY + X for y in range ( Y ): m_norm_y = m_norm [ y ] A_inv_y = A_inv [ iy , :] var_log_my = var_munm_norm [ jy , jy ] / m_norm_y / m_norm_y slice_y = slice ( y , XY , Y ) covar_term = var_muhat_norm [:, jy ] + np . sum ( var_muhat_norm [:, slice_y ], 1 ) cov_b_logmy = ( A_inv_y @ z_unweighted_T @ covar_term ) / m_norm_y vy_var = variance_gamma [ iy , iy ] + var_log_my + 2.0 * cov_b_logmy v_std [ y ] = sqrt ( vy_var ) iy += 1 jy += 1 results = PoissonGLMResults ( X = X , Y = Y , K = K , number_households = n_households , number_individuals = n_individuals , estimated_gamma = gamma_est , estimated_Phi = Phi_est , estimated_beta = beta_est , estimated_u = u_est , estimated_v = v_est , variance_gamma = variance_gamma , stderrs_gamma = stderrs_gamma , stderrs_beta = beta_std , stderrs_u = u_std , stderrs_v = v_std , ) return results","title":"poisson_glm"},{"location":"poisson_glm/#poisson_glm-module","text":"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM.","title":"poisson_glm module"},{"location":"poisson_glm/#cupid_matching.poisson_glm.choo_siow_poisson_glm","text":"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases ndarray an (X, Y, K) array of bases required tol Optional[float] tolerance level for linear_model.PoissonRegressor.fit 1e-12 max_iter Optional[int] maximum number of iterations for linear_model.PoissonRegressor.fit 10000 verbose Optional[int] defines how much output we want (0 = least) 1 Returns: Type Description PoissonGLMResults a PoissonGLMResults instance Examples: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 n_households = 1e6 X , Y , K = 4 , 3 , 6 # we setup a quadratic set of basis functions phi_bases = np . zeros (( X , Y , K )) phi_bases [:, :, 0 ] = 1 for x in range ( X ): phi_bases [ x , :, 1 ] = x phi_bases [ x , :, 3 ] = x * x for y in range ( Y ): phi_bases [ x , y , 4 ] = x * y for y in range ( Y ): phi_bases [:, y , 2 ] = y phi_bases [:, y , 5 ] = y * y lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np . ones ( X ) m = np . ones ( Y ) choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () results = choo_siow_poisson_glm ( mus_sim , phi_bases ) # compare true and estimated parameters results . print_results ( lambda_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ) ) Source code in cupid_matching/poisson_glm.py def choo_siow_poisson_glm ( muhat : Matching , phi_bases : np . ndarray , tol : Optional [ float ] = 1e-12 , max_iter : Optional [ int ] = 10000 , verbose : Optional [ int ] = 1 , ) -> PoissonGLMResults : \"\"\"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases tol: tolerance level for `linear_model.PoissonRegressor.fit` max_iter: maximum number of iterations for `linear_model.PoissonRegressor.fit` verbose: defines how much output we want (0 = least) Returns: a `PoissonGLMResults` instance Example: ```py n_households = 1e6 X, Y, K = 4, 3, 6 # we setup a quadratic set of basis functions phi_bases = np.zeros((X, Y, K)) phi_bases[:, :, 0] = 1 for x in range(X): phi_bases[x, :, 1] = x phi_bases[x, :, 3] = x * x for y in range(Y): phi_bases[x, y, 4] = x * y for y in range(Y): phi_bases[:, y, 2] = y phi_bases[:, y, 5] = y * y lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np.ones(X) m = np.ones(Y) choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack() results = choo_siow_poisson_glm(mus_sim, phi_bases) # compare true and estimated parameters results.print_results( lambda_true, u_true=-np.log(mux0_sim / n_sim), v_true=-np.log(mu0y_sim / m_sim) ) ``` \"\"\" try_sparse = False X , Y , K = phi_bases . shape XY = X * Y n_rows = XY + X + Y n_cols = X + Y + K # the vector of weights for the Poisson regression w = np . concatenate (( 2 * np . ones ( XY ), np . ones ( X + Y ))) # reshape the bases phi_mat = _make_XY_K_mat ( phi_bases ) if try_sparse : w_mat = spr . csr_matrix ( np . concatenate (( 2 * np . ones ( XY , n_cols ), np . ones ( X + Y , n_cols ))) ) # construct the Z matrix ones_X = spr . csr_matrix ( np . ones (( X , 1 ))) ones_Y = spr . csr_matrix ( np . ones (( Y , 1 ))) zeros_XK = spr . csr_matrix ( np . zeros (( X , K ))) zeros_YK = spr . csr_matrix ( np . zeros (( Y , K ))) zeros_XY = spr . csr_matrix ( np . zeros (( X , Y ))) zeros_YX = spr . csr_matrix ( np . zeros (( Y , X ))) id_X = spr . csr_matrix ( np . eye ( X )) id_Y = spr . csr_matrix ( np . eye ( Y )) Z_unweighted = spr . vstack ( [ spr . hstack ([ - spr . kron ( id_X , ones_Y ), - spr . kron ( ones_X , id_Y ), phi_mat ]), spr . hstack ([ - id_X , zeros_XY , zeros_XK ]), spr . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w_mat else : ones_X = np . ones (( X , 1 )) ones_Y = np . ones (( Y , 1 )) zeros_XK = np . zeros (( X , K )) zeros_YK = np . zeros (( Y , K )) zeros_XY = np . zeros (( X , Y )) zeros_YX = np . zeros (( Y , X )) id_X = np . eye ( X ) id_Y = np . eye ( Y ) Z_unweighted = np . vstack ( [ np . hstack ([ - np . kron ( id_X , ones_Y ), - np . kron ( ones_X , id_Y ), phi_mat ]), np . hstack ([ - id_X , zeros_XY , zeros_XK ]), np . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w . reshape (( - 1 , 1 )) _ , _ , _ , n , m = muhat . unpack () var_muhat , var_munm = _variance_muhat ( muhat ) ( muxyhat_norm , var_muhat_norm , var_munm_norm , n_households , n_individuals , ) = _prepare_data ( muhat , var_muhat , var_munm ) clf = linear_model . PoissonRegressor ( fit_intercept = False , tol = tol , verbose = verbose , alpha = 0 , max_iter = max_iter ) clf . fit ( Z , muxyhat_norm , sample_weight = w ) gamma_est = clf . coef_ # we compute the variance-covariance of the estimator nr , nc = Z . shape exp_Zg = np . exp ( Z @ gamma_est ) . reshape ( n_rows ) A_hat = np . zeros (( nc , nc )) B_hat = np . zeros (( nc , nc )) for i in range ( nr ): Zi = Z [ i , :] wi = w [ i ] A_hat += wi * exp_Zg [ i ] * np . outer ( Zi , Zi ) for j in range ( nr ): Zj = Z [ j , :] B_hat += wi * w [ j ] * var_muhat_norm [ i , j ] * np . outer ( Zi , Zj ) A_inv = spla . inv ( A_hat ) variance_gamma = A_inv @ B_hat @ A_inv stderrs_gamma = np . sqrt ( np . diag ( variance_gamma )) beta_est = gamma_est [ - K :] beta_std = stderrs_gamma [ - K :] Phi_est = phi_bases @ beta_est # we correct for the effect of the normalization n_norm = n / n_individuals m_norm = m / n_individuals u_est = gamma_est [: X ] + np . log ( n_norm ) v_est = gamma_est [ X : - K ] + np . log ( m_norm ) # since u = a + log(n_norm) we also need to adjust the estimated variance z_unweighted_T = Z_unweighted . T u_std = np . zeros ( X ) ix = XY for x in range ( X ): n_norm_x = n_norm [ x ] A_inv_x = A_inv [ x , :] var_log_nx = var_munm_norm [ ix , ix ] / n_norm_x / n_norm_x slice_x = slice ( x * Y , ( x + 1 ) * Y ) covar_term = var_muhat_norm [:, ix ] + np . sum ( var_muhat_norm [:, slice_x ], 1 ) cov_a_lognx = ( A_inv_x @ z_unweighted_T @ covar_term ) / n_norm_x ux_var = variance_gamma [ x , x ] + var_log_nx + 2.0 * cov_a_lognx u_std [ x ] = sqrt ( ux_var ) ix += 1 v_std = stderrs_gamma [ X : - K ] iy , jy = X , XY + X for y in range ( Y ): m_norm_y = m_norm [ y ] A_inv_y = A_inv [ iy , :] var_log_my = var_munm_norm [ jy , jy ] / m_norm_y / m_norm_y slice_y = slice ( y , XY , Y ) covar_term = var_muhat_norm [:, jy ] + np . sum ( var_muhat_norm [:, slice_y ], 1 ) cov_b_logmy = ( A_inv_y @ z_unweighted_T @ covar_term ) / m_norm_y vy_var = variance_gamma [ iy , iy ] + var_log_my + 2.0 * cov_b_logmy v_std [ y ] = sqrt ( vy_var ) iy += 1 jy += 1 results = PoissonGLMResults ( X = X , Y = Y , K = K , number_households = n_households , number_individuals = n_individuals , estimated_gamma = gamma_est , estimated_Phi = Phi_est , estimated_beta = beta_est , estimated_u = u_est , estimated_v = v_est , variance_gamma = variance_gamma , stderrs_gamma = stderrs_gamma , stderrs_beta = beta_std , stderrs_u = u_std , stderrs_v = v_std , ) return results","title":"choo_siow_poisson_glm()"},{"location":"poisson_glm_utils/","text":"poisson_glm_utils module \u00b6 Utilities for Poisson GLM. PoissonGLMResults dataclass \u00b6 Stores and formats the estimation results. Parameters: Name Type Description Default X int int required Y int int required K int int required number_households int int required number_individuals int int required estimated_gamma ndarray np.ndarray required variance_gamma ndarray np.ndarray required stderrs_gamma ndarray np.ndarray required estimated_beta ndarray np.ndarray required estimated_u ndarray np.ndarray required estimated_v ndarray np.ndarray required stderrs_beta ndarray np.ndarray required stderrs_u ndarray np.ndarray required stderrs_v ndarray np.ndarray required estimated_Phi ndarray np.ndarray required Source code in cupid_matching/poisson_glm_utils.py class PoissonGLMResults : \"\"\"Stores and formats the estimation results. Args: X: int Y: int K: int number_households: int number_individuals: int estimated_gamma: np.ndarray variance_gamma: np.ndarray stderrs_gamma: np.ndarray estimated_beta: np.ndarray estimated_u: np.ndarray estimated_v: np.ndarray stderrs_beta: np.ndarray stderrs_u: np.ndarray stderrs_v: np.ndarray estimated_Phi: np.ndarray \"\"\" X : int Y : int K : int number_households : int number_individuals : int estimated_gamma : np . ndarray variance_gamma : np . ndarray stderrs_gamma : np . ndarray estimated_beta : np . ndarray estimated_u : np . ndarray estimated_v : np . ndarray stderrs_beta : np . ndarray stderrs_u : np . ndarray stderrs_v : np . ndarray estimated_Phi : np . ndarray def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" print_stars ( \"Estimating a Choo and Siow model by Poisson GLM.\" ) model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += ( \"The estimated basis coefficients (and their standard errors) are \\n\\n \" ) for i in range ( self . K ): repr_str += ( f \" base_ { i + 1 } : { self . estimated_beta [ i ] : > 10.3f } \" + f \"( { self . stderrs_beta [ i ] : .3f } ) \\n \" ) repr_str += \"The estimated utilities of men (and their standard errors) are \\n\\n \" for i in range ( self . X ): repr_str += ( f \" u_ { i + 1 } : { self . estimated_u [ i ] : > 10.3f } \" + f \"( { self . stderrs_u [ i ] : .3f } ) \\n \" ) repr_str += ( \"The estimated utilities of women (and their standard errors) are \\n\\n \" ) for i in range ( self . Y ): repr_str += ( f \" v { i + 1 } : { self . estimated_v [ i ] : > 10.3f } \" + f \"( { self . stderrs_v [ i ] : .3f } ) \\n \" ) return repr_str + line_stars def print_results ( self , lambda_true : Optional [ np . ndarray ] = None , u_true : Optional [ np . ndarray ] = None , v_true : Optional [ np . ndarray ] = None , ) -> float : estimates_beta = self . estimated_beta stderrs_beta = self . stderrs_beta if lambda_true is None : repr_str = \"The estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += f \" base { i + 1 } : { lambda_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) estimates_u = self . estimated_u stderrs_u = self . stderrs_u if u_true is None : repr_str = \"The estimated utilities for men \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_u ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_u [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated utilities for men\" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_u ): repr_str += f \" u_ { i + 1 } : { u_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_u [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) estimates_v = self . estimated_v stderrs_v = self . stderrs_v if v_true is None : repr_str = \"The estimated utilities for women \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_v ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_v [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated utilities for women\" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_v ): repr_str += f \" v_ { i + 1 } : { v_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_v [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) if lambda_true is not None : discrepancy = npmaxabs ( lambda_true - estimates_beta ) print_stars ( f \"The true-estimated discrepancy is { discrepancy } \" ) return discrepancy","title":"poisson_glm_utils"},{"location":"poisson_glm_utils/#poisson_glm_utils-module","text":"Utilities for Poisson GLM.","title":"poisson_glm_utils module"},{"location":"poisson_glm_utils/#cupid_matching.poisson_glm_utils.PoissonGLMResults","text":"Stores and formats the estimation results. Parameters: Name Type Description Default X int int required Y int int required K int int required number_households int int required number_individuals int int required estimated_gamma ndarray np.ndarray required variance_gamma ndarray np.ndarray required stderrs_gamma ndarray np.ndarray required estimated_beta ndarray np.ndarray required estimated_u ndarray np.ndarray required estimated_v ndarray np.ndarray required stderrs_beta ndarray np.ndarray required stderrs_u ndarray np.ndarray required stderrs_v ndarray np.ndarray required estimated_Phi ndarray np.ndarray required Source code in cupid_matching/poisson_glm_utils.py class PoissonGLMResults : \"\"\"Stores and formats the estimation results. Args: X: int Y: int K: int number_households: int number_individuals: int estimated_gamma: np.ndarray variance_gamma: np.ndarray stderrs_gamma: np.ndarray estimated_beta: np.ndarray estimated_u: np.ndarray estimated_v: np.ndarray stderrs_beta: np.ndarray stderrs_u: np.ndarray stderrs_v: np.ndarray estimated_Phi: np.ndarray \"\"\" X : int Y : int K : int number_households : int number_individuals : int estimated_gamma : np . ndarray variance_gamma : np . ndarray stderrs_gamma : np . ndarray estimated_beta : np . ndarray estimated_u : np . ndarray estimated_v : np . ndarray stderrs_beta : np . ndarray stderrs_u : np . ndarray stderrs_v : np . ndarray estimated_Phi : np . ndarray def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" print_stars ( \"Estimating a Choo and Siow model by Poisson GLM.\" ) model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += ( \"The estimated basis coefficients (and their standard errors) are \\n\\n \" ) for i in range ( self . K ): repr_str += ( f \" base_ { i + 1 } : { self . estimated_beta [ i ] : > 10.3f } \" + f \"( { self . stderrs_beta [ i ] : .3f } ) \\n \" ) repr_str += \"The estimated utilities of men (and their standard errors) are \\n\\n \" for i in range ( self . X ): repr_str += ( f \" u_ { i + 1 } : { self . estimated_u [ i ] : > 10.3f } \" + f \"( { self . stderrs_u [ i ] : .3f } ) \\n \" ) repr_str += ( \"The estimated utilities of women (and their standard errors) are \\n\\n \" ) for i in range ( self . Y ): repr_str += ( f \" v { i + 1 } : { self . estimated_v [ i ] : > 10.3f } \" + f \"( { self . stderrs_v [ i ] : .3f } ) \\n \" ) return repr_str + line_stars def print_results ( self , lambda_true : Optional [ np . ndarray ] = None , u_true : Optional [ np . ndarray ] = None , v_true : Optional [ np . ndarray ] = None , ) -> float : estimates_beta = self . estimated_beta stderrs_beta = self . stderrs_beta if lambda_true is None : repr_str = \"The estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += f \" base { i + 1 } : { lambda_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) estimates_u = self . estimated_u stderrs_u = self . stderrs_u if u_true is None : repr_str = \"The estimated utilities for men \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_u ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_u [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated utilities for men\" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_u ): repr_str += f \" u_ { i + 1 } : { u_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_u [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) estimates_v = self . estimated_v stderrs_v = self . stderrs_v if v_true is None : repr_str = \"The estimated utilities for women \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_v ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_v [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated utilities for women\" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_v ): repr_str += f \" v_ { i + 1 } : { v_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_v [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) if lambda_true is not None : discrepancy = npmaxabs ( lambda_true - estimates_beta ) print_stars ( f \"The true-estimated discrepancy is { discrepancy } \" ) return discrepancy","title":"PoissonGLMResults"},{"location":"utils/","text":"utils module \u00b6 This module contains some utility programs used by the package. ScalarFunctionAndGradient \u00b6 Type of f(v, args, gr) that returns a scalar value and also a gradient if gr is True bs_error_abort ( msg = 'error, aborting' ) \u00b6 Report error and exits with code 1 Parameters: Name Type Description Default msg str specifies the error message 'error, aborting' Returns: Type Description None nothing Source code in cupid_matching/utils.py def bs_error_abort ( msg : str = \"error, aborting\" ) -> None : \"\"\"Report error and exits with code 1 Args: msg: specifies the error message Returns: nothing \"\"\" print_stars ( f \" { bs_name_func ( 3 ) } : { msg } \" ) sys . exit ( 1 ) bs_name_func ( back = 2 ) \u00b6 Get the name of the current function, or further back in the stack Parameters: Name Type Description Default back int 2 for the current function, 3 for the function that called it, etc 2 Returns: Type Description str the name of the function requested Source code in cupid_matching/utils.py def bs_name_func ( back : int = 2 ) -> str : \"\"\"Get the name of the current function, or further back in the stack Args: back: 2 for the current function, 3 for the function that called it, etc Returns: the name of the function requested \"\"\" stack = extract_stack () func_name = stack [ - back ][ 2 ] return func_name check_gradient_scalar_function ( fg , p , args , mode = 'central' , EPS = 1e-06 ) \u00b6 Checks the gradient of a scalar function. Parameters: Name Type Description Default fg Callable[[numpy.ndarray, List, Optional[bool]], Union[float, Tuple[float, numpy.ndarray]]] should return the scalar value, and the gradient if its gr argument is True required p ndarray where we are checking the gradient required args List other arguments passed to fg required mode str \"central\" or \"forward\" derivatives 'central' EPS float the step for forward or central derivatives 1e-06 Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray] the analytic and numeric gradients Source code in cupid_matching/utils.py def check_gradient_scalar_function ( fg : ScalarFunctionAndGradient , p : np . ndarray , args : List , mode : str = \"central\" , EPS : float = 1e-6 , ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Checks the gradient of a scalar function. Args: fg: should return the scalar value, and the gradient if its `gr` argument is `True` p: where we are checking the gradient args: other arguments passed to `fg` mode: \"central\" or \"forward\" derivatives EPS: the step for forward or central derivatives Returns: the analytic and numeric gradients \"\"\" f0 , f_grad = fg ( p , args , gr = True ) print_stars ( \"checking the gradient: analytic, numeric\" ) g = np . zeros_like ( p ) if mode == \"central\" : for i , x in enumerate ( p ): p1 = p . copy () p1 [ i ] = x + EPS f_plus = fg ( p1 , args , gr = False ) p1 [ i ] -= 2.0 * EPS f_minus = fg ( p1 , args , gr = False ) g [ i ] = ( f_plus - f_minus ) / ( 2.0 * EPS ) print ( f \" { i } : { f_grad [ i ] } , { g [ i ] } \" ) elif mode == \"forward\" : for i , x in enumerate ( p ): p1 = p . copy () p1 [ i ] = x + EPS f_plus = fg ( p1 , args , gr = False ) g [ i ] = ( f_plus - f0 ) / EPS print ( f \" { i } : { f_grad [ i ] } , { g [ i ] } \" ) else : bs_error_abort ( \"mode must be 'central' or 'forward'\" ) return f_grad , g der_nppow ( a , b ) \u00b6 evaluates the derivatives in a and b of element-by-element $a^b$ :param np.array a: :param Union[int, float, np.array] b: if an array, should have the same shape as a :return: a pair of two arrays of the same shape as a Source code in cupid_matching/utils.py def der_nppow ( a : np . array , b : Union [ int , float , np . array ]) -> np . array : \"\"\" evaluates the derivatives in a and b of element-by-element $a^b$ :param np.array a: :param Union[int, float, np.array] b: if an array, should have the same shape as `a` :return: a pair of two arrays of the same shape as `a` \"\"\" mina = np . min ( a ) if mina <= 0 : print_stars ( \"All elements of a must be positive in der_nppow!\" ) sys . exit ( 1 ) if isinstance ( b , ( int , float )): a_pow_b = a ** b return ( b * a_pow_b / a , a_pow_b * log ( a )) else : if a . shape != b . shape : print_stars ( \"nppow: b is not a number or an array of the same shape as a!\" ) sys . exit ( 1 ) avec = a . ravel () bvec = b . ravel () a_pow_b = avec ** bvec der_wrt_a = a_pow_b * bvec / avec der_wrt_b = a_pow_b * nplog ( avec ) return ( der_wrt_a . reshape ( a . shape ), der_wrt_b . reshape ( a . shape )) describe_array ( v , name = 'The array' ) \u00b6 Descriptive statistics on an array interpreted as a vector Parameters: Name Type Description Default v ndarray the array required name str its name 'The array' Returns: Type Description <function namedtuple at 0x7f4aadaefee0> a DescribeResult namedtuple Source code in cupid_matching/utils.py def describe_array ( v : np . ndarray , name : str = \"The array\" ) -> namedtuple : \"\"\"Descriptive statistics on an array interpreted as a vector Args: v: the array name: its name Returns: a `DescribeResult` namedtuple \"\"\" print_stars ( f \" { name } has:\" ) d = sts . describe ( v , None ) print ( f \"Number of elements: { d . nobs } \" ) print ( f \"Minimum: { d . minmax [ 0 ] } \" ) print ( f \"Maximum: { d . minmax [ 1 ] } \" ) print ( f \"Mean: { d . mean } \" ) print ( f \"Stderr: { sqrt ( d . variance ) } \" ) return d npexp ( a , deriv = False , bigx = 30.0 , verbose = False ) \u00b6 $C^2$ extension of $\\exp(a)$ above bigx Parameters: Name Type Description Default a ndarray a Numpy array required deriv bool if True , the first derivative is also returned False bigx float an upper bound 30.0 verbose bool whether diagnoses are printed False Returns: Type Description bigx upper bound $\\exp(a)$ $C^2$-extended above bigx , with its derivative if deriv is True Source code in cupid_matching/utils.py def npexp ( a : np . ndarray , deriv : bool = False , bigx : float = 30.0 , verbose : bool = False ) -> Union [ np . ndarray , Tuple [ np . ndarray , np . ndarray ]]: \"\"\" $C^2$ extension of $\\exp(a)$ above `bigx` Args: a: a Numpy array deriv: if `True`, the first derivative is also returned bigx: an upper bound verbose: whether diagnoses are printed Returns: bigx: upper bound $\\exp(a)$ $C^2$-extended above `bigx`, with its derivative if `deriv` is `True` \"\"\" if np . max ( a ) < bigx : expa = np . exp ( a ) return [ expa , expa ] if deriv else expa else : exparr = np . exp ( np . minimum ( a , bigx )) ebigx = exp ( bigx ) darr = a - bigx exparr_larger = ebigx * ( 1.0 + darr * ( 1.0 + 0.5 * darr )) if verbose : n_large_args = np . sum ( a > bigx ) if n_large_args > 0 : finals = \"s\" if n_large_args > 1 else \"\" print ( f \"npexp: { n_large_args } argument { finals } larger than { bigx } : maxi = { np . max ( a ) } \" ) expa = np . where ( a < bigx , exparr , exparr_larger ) if deriv : der_exparr = np . exp ( np . minimum ( a , bigx )) der_exparr_larger = ebigx * ( 1.0 + darr ) der_expa = np . where ( a < bigx , der_exparr , der_exparr_larger ) return expa , der_expa else : return expa nplog ( a , deriv = False , eps = 1e-30 , verbose = False ) \u00b6 $C^2$ extension of $\\ln(a)$ below eps Parameters: Name Type Description Default a ndarray a Numpy array required deriv bool if True , the first derivative is also returned False eps float a lower bound 1e-30 verbose bool whether diagnoses are printed False Returns: Type Description Union[numpy.ndarray, Tuple[numpy.ndarray, numpy.ndarray]] $\\ln(a)$ $C^2$-extended below eps , with its derivative if deriv is True Source code in cupid_matching/utils.py def nplog ( a : np . ndarray , deriv : bool = False , eps : float = 1e-30 , verbose : bool = False ) -> Union [ np . ndarray , Tuple [ np . ndarray , np . ndarray ]]: \"\"\"$C^2$ extension of $\\ln(a)$ below `eps` Args: a: a Numpy array deriv: if `True`, the first derivative is also returned eps: a lower bound verbose: whether diagnoses are printed Returns: $\\ln(a)$ $C^2$-extended below `eps`, with its derivative if `deriv` is `True` \"\"\" if np . min ( a ) > eps : loga = np . log ( a ) return [ loga , 1.0 / a ] if deriv else loga else : logarreps = np . log ( np . maximum ( a , eps )) logarr_smaller = log ( eps ) - ( eps - a ) * ( 3.0 * eps - a ) / ( 2.0 * eps * eps ) if verbose : n_small_args = np . sum ( a < eps ) if n_small_args > 0 : finals = \"s\" if n_small_args > 1 else \"\" print ( f \"nplog: { n_small_args } argument { finals } smaller than { eps } : mini = { np . min ( a ) } \" ) loga = np . where ( a > eps , logarreps , logarr_smaller ) if deriv : der_logarreps = 1.0 / np . maximum ( a , eps ) der_logarr_smaller = ( 2.0 * eps - a ) / ( eps * eps ) der_loga = np . where ( a > eps , der_logarreps , der_logarr_smaller ) return loga , der_loga else : return loga npmaxabs ( a ) \u00b6 The maximum absolute value in an array Parameters: Name Type Description Default a ndarray the array required Returns: Type Description float $\\max{ ert a ert}$ Source code in cupid_matching/utils.py def npmaxabs ( a : np . ndarray ) -> float : \"\"\"The maximum absolute value in an array Args: a: the array Returns: $\\max{\\vert a \\vert}$ \"\"\" return np . max ( np . abs ( a )) nppow ( a , b , deriv = False ) \u00b6 Evaluates $a^b$ element-by-element Parameters: Name Type Description Default a ndarray a Numpy array required b Union[int, float, numpy.ndarray] if an array, it should have the same shape as a required deriv bool if True , the first derivatives wrt a and b are also returned False Returns: Type Description Union[<built-in function array>, Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]] an array of the same shape as a , and if deriv is True , the derivatives wrt a and b Source code in cupid_matching/utils.py def nppow ( a : np . ndarray , b : Union [ int , float , np . ndarray ], deriv : bool = False ) -> Union [ np . array , Tuple [ np . ndarray , np . ndarray , np . ndarray ]]: \"\"\"Evaluates $a^b$ element-by-element Args: a: a Numpy array b: if an array, it should have the same shape as `a` deriv: if `True`, the first derivatives wrt `a` and `b` are also returned Returns: an array of the same shape as `a`, and if `deriv` is `True`, the derivatives wrt `a` and `b` \"\"\" mina = np . min ( a ) if mina <= 0 : bs_error_abort ( \"All elements of a must be positive!\" ) if isinstance ( b , ( int , float )): a_pow_b = a ** b if deriv : return ( a ** b , b * a_pow_b / a , a_pow_b * log ( a )) else : return a_pow_b else : if a . shape != b . shape : bs_error_abort ( f \"a has shape { a . shape } and b has shape { b . shape } \" ) avec = a . ravel () bvec = b . ravel () a_pow_b = avec ** bvec if deriv : der_wrt_a = a_pow_b * bvec / avec der_wrt_b = a_pow_b * nplog ( avec ) return ( a_pow_b . reshape ( a . shape ), der_wrt_a . reshape ( a . shape ), der_wrt_b . reshape ( a . shape ), ) else : return a_pow_b . reshape ( a . shape ) nprepeat_col ( v , n ) \u00b6 Creates a matrix with n columns, all equal to v Parameters: Name Type Description Default v ndarray a vector of size m required n int the number of columns requested required :return: a matrix of shape (m, n) Source code in cupid_matching/utils.py def nprepeat_col ( v : np . ndarray , n : int ) -> np . ndarray : \"\"\"Creates a matrix with `n` columns, all equal to `v` Args: v: a vector of size `m` n: the number of columns requested :return: a matrix of shape `(m, n)` \"\"\" _ = test_vector ( v , \"nprepeat_col\" ) return np . repeat ( v [:, np . newaxis ], n , axis = 1 ) nprepeat_row ( v , m ) \u00b6 Creates a matrix with m rows, all equal to v Parameters: Name Type Description Default v ndarray a vector of size n required m int the number of rows requested required Returns: Type Description ndarray a matrix of shape (m, n) Source code in cupid_matching/utils.py def nprepeat_row ( v : np . ndarray , m : int ) -> np . ndarray : \"\"\" Creates a matrix with `m` rows, all equal to `v` Args: v: a vector of size `n` m: the number of rows requested Returns: a matrix of shape `(m, n)` \"\"\" _ = test_vector ( v , \"nprepeat_row\" ) return np . repeat ( v [ np . newaxis , :], m , axis = 0 ) print_stars ( title = None , n = 70 ) \u00b6 Prints a starred line, or two around the title Parameters: Name Type Description Default title str an optional title None n int the number of stars on the line 70 Returns: Type Description None nothing Source code in cupid_matching/utils.py def print_stars ( title : str = None , n : int = 70 ) -> None : \"\"\"Prints a starred line, or two around the title Args: title: an optional title n: the number of stars on the line Returns: nothing \"\"\" line_stars = \"*\" * n print () print ( line_stars ) if title : print ( title . center ( n )) print ( line_stars ) print () test_matrix ( x , fun_name = None ) \u00b6 Tests that x is a matrix; aborts otherwise Parameters: Name Type Description Default x ndarray a potential matrix required fun_name str the name of the calling function None Returns: Type Description Tuple[int, int] the shape of x if it is a matrix Source code in cupid_matching/utils.py def test_matrix ( x : np . ndarray , fun_name : str = None ) -> Tuple [ int , int ]: \"\"\"Tests that `x` is a matrix; aborts otherwise Args: x: a potential matrix fun_name: the name of the calling function Returns: the shape of `x` if it is a matrix \"\"\" fun_str = [ \"\" if fun_name is None else fun_name + \":\" ] if not isinstance ( x , np . ndarray ): bs_error_abort ( f \" { fun_str } x should be a Numpy array\" ) ndims_x = x . ndim if ndims_x != 2 : bs_error_abort ( f \" { fun_str } x should have two dimensions, not { ndims_x } \" ) return x . shape test_vector ( x , fun_name = None ) \u00b6 Tests that x is a vector; aborts otherwise Parameters: Name Type Description Default x ndarray a potential vector required fun_name str the name of the calling function None Returns: Type Description int the size of x if it is a vector Source code in cupid_matching/utils.py def test_vector ( x : np . ndarray , fun_name : str = None ) -> int : \"\"\"Tests that `x` is a vector; aborts otherwise Args: x: a potential vector fun_name: the name of the calling function Returns: the size of `x` if it is a vector \"\"\" fun_str = [ \"\" if fun_name is None else fun_name + \":\" ] if not isinstance ( x , np . ndarray ): bs_error_abort ( f \" { fun_str } x should be a Numpy array\" ) ndims_x = x . ndim if ndims_x != 1 : bs_error_abort ( f \" { fun_str } x should have one dimension, not { ndims_x } \" ) return x . size","title":"utils"},{"location":"utils/#utils-module","text":"This module contains some utility programs used by the package.","title":"utils module"},{"location":"utils/#cupid_matching.utils.ScalarFunctionAndGradient","text":"Type of f(v, args, gr) that returns a scalar value and also a gradient if gr is True","title":"ScalarFunctionAndGradient"},{"location":"utils/#cupid_matching.utils.bs_error_abort","text":"Report error and exits with code 1 Parameters: Name Type Description Default msg str specifies the error message 'error, aborting' Returns: Type Description None nothing Source code in cupid_matching/utils.py def bs_error_abort ( msg : str = \"error, aborting\" ) -> None : \"\"\"Report error and exits with code 1 Args: msg: specifies the error message Returns: nothing \"\"\" print_stars ( f \" { bs_name_func ( 3 ) } : { msg } \" ) sys . exit ( 1 )","title":"bs_error_abort()"},{"location":"utils/#cupid_matching.utils.bs_name_func","text":"Get the name of the current function, or further back in the stack Parameters: Name Type Description Default back int 2 for the current function, 3 for the function that called it, etc 2 Returns: Type Description str the name of the function requested Source code in cupid_matching/utils.py def bs_name_func ( back : int = 2 ) -> str : \"\"\"Get the name of the current function, or further back in the stack Args: back: 2 for the current function, 3 for the function that called it, etc Returns: the name of the function requested \"\"\" stack = extract_stack () func_name = stack [ - back ][ 2 ] return func_name","title":"bs_name_func()"},{"location":"utils/#cupid_matching.utils.check_gradient_scalar_function","text":"Checks the gradient of a scalar function. Parameters: Name Type Description Default fg Callable[[numpy.ndarray, List, Optional[bool]], Union[float, Tuple[float, numpy.ndarray]]] should return the scalar value, and the gradient if its gr argument is True required p ndarray where we are checking the gradient required args List other arguments passed to fg required mode str \"central\" or \"forward\" derivatives 'central' EPS float the step for forward or central derivatives 1e-06 Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray] the analytic and numeric gradients Source code in cupid_matching/utils.py def check_gradient_scalar_function ( fg : ScalarFunctionAndGradient , p : np . ndarray , args : List , mode : str = \"central\" , EPS : float = 1e-6 , ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Checks the gradient of a scalar function. Args: fg: should return the scalar value, and the gradient if its `gr` argument is `True` p: where we are checking the gradient args: other arguments passed to `fg` mode: \"central\" or \"forward\" derivatives EPS: the step for forward or central derivatives Returns: the analytic and numeric gradients \"\"\" f0 , f_grad = fg ( p , args , gr = True ) print_stars ( \"checking the gradient: analytic, numeric\" ) g = np . zeros_like ( p ) if mode == \"central\" : for i , x in enumerate ( p ): p1 = p . copy () p1 [ i ] = x + EPS f_plus = fg ( p1 , args , gr = False ) p1 [ i ] -= 2.0 * EPS f_minus = fg ( p1 , args , gr = False ) g [ i ] = ( f_plus - f_minus ) / ( 2.0 * EPS ) print ( f \" { i } : { f_grad [ i ] } , { g [ i ] } \" ) elif mode == \"forward\" : for i , x in enumerate ( p ): p1 = p . copy () p1 [ i ] = x + EPS f_plus = fg ( p1 , args , gr = False ) g [ i ] = ( f_plus - f0 ) / EPS print ( f \" { i } : { f_grad [ i ] } , { g [ i ] } \" ) else : bs_error_abort ( \"mode must be 'central' or 'forward'\" ) return f_grad , g","title":"check_gradient_scalar_function()"},{"location":"utils/#cupid_matching.utils.der_nppow","text":"evaluates the derivatives in a and b of element-by-element $a^b$ :param np.array a: :param Union[int, float, np.array] b: if an array, should have the same shape as a :return: a pair of two arrays of the same shape as a Source code in cupid_matching/utils.py def der_nppow ( a : np . array , b : Union [ int , float , np . array ]) -> np . array : \"\"\" evaluates the derivatives in a and b of element-by-element $a^b$ :param np.array a: :param Union[int, float, np.array] b: if an array, should have the same shape as `a` :return: a pair of two arrays of the same shape as `a` \"\"\" mina = np . min ( a ) if mina <= 0 : print_stars ( \"All elements of a must be positive in der_nppow!\" ) sys . exit ( 1 ) if isinstance ( b , ( int , float )): a_pow_b = a ** b return ( b * a_pow_b / a , a_pow_b * log ( a )) else : if a . shape != b . shape : print_stars ( \"nppow: b is not a number or an array of the same shape as a!\" ) sys . exit ( 1 ) avec = a . ravel () bvec = b . ravel () a_pow_b = avec ** bvec der_wrt_a = a_pow_b * bvec / avec der_wrt_b = a_pow_b * nplog ( avec ) return ( der_wrt_a . reshape ( a . shape ), der_wrt_b . reshape ( a . shape ))","title":"der_nppow()"},{"location":"utils/#cupid_matching.utils.describe_array","text":"Descriptive statistics on an array interpreted as a vector Parameters: Name Type Description Default v ndarray the array required name str its name 'The array' Returns: Type Description <function namedtuple at 0x7f4aadaefee0> a DescribeResult namedtuple Source code in cupid_matching/utils.py def describe_array ( v : np . ndarray , name : str = \"The array\" ) -> namedtuple : \"\"\"Descriptive statistics on an array interpreted as a vector Args: v: the array name: its name Returns: a `DescribeResult` namedtuple \"\"\" print_stars ( f \" { name } has:\" ) d = sts . describe ( v , None ) print ( f \"Number of elements: { d . nobs } \" ) print ( f \"Minimum: { d . minmax [ 0 ] } \" ) print ( f \"Maximum: { d . minmax [ 1 ] } \" ) print ( f \"Mean: { d . mean } \" ) print ( f \"Stderr: { sqrt ( d . variance ) } \" ) return d","title":"describe_array()"},{"location":"utils/#cupid_matching.utils.npexp","text":"$C^2$ extension of $\\exp(a)$ above bigx Parameters: Name Type Description Default a ndarray a Numpy array required deriv bool if True , the first derivative is also returned False bigx float an upper bound 30.0 verbose bool whether diagnoses are printed False Returns: Type Description bigx upper bound $\\exp(a)$ $C^2$-extended above bigx , with its derivative if deriv is True Source code in cupid_matching/utils.py def npexp ( a : np . ndarray , deriv : bool = False , bigx : float = 30.0 , verbose : bool = False ) -> Union [ np . ndarray , Tuple [ np . ndarray , np . ndarray ]]: \"\"\" $C^2$ extension of $\\exp(a)$ above `bigx` Args: a: a Numpy array deriv: if `True`, the first derivative is also returned bigx: an upper bound verbose: whether diagnoses are printed Returns: bigx: upper bound $\\exp(a)$ $C^2$-extended above `bigx`, with its derivative if `deriv` is `True` \"\"\" if np . max ( a ) < bigx : expa = np . exp ( a ) return [ expa , expa ] if deriv else expa else : exparr = np . exp ( np . minimum ( a , bigx )) ebigx = exp ( bigx ) darr = a - bigx exparr_larger = ebigx * ( 1.0 + darr * ( 1.0 + 0.5 * darr )) if verbose : n_large_args = np . sum ( a > bigx ) if n_large_args > 0 : finals = \"s\" if n_large_args > 1 else \"\" print ( f \"npexp: { n_large_args } argument { finals } larger than { bigx } : maxi = { np . max ( a ) } \" ) expa = np . where ( a < bigx , exparr , exparr_larger ) if deriv : der_exparr = np . exp ( np . minimum ( a , bigx )) der_exparr_larger = ebigx * ( 1.0 + darr ) der_expa = np . where ( a < bigx , der_exparr , der_exparr_larger ) return expa , der_expa else : return expa","title":"npexp()"},{"location":"utils/#cupid_matching.utils.nplog","text":"$C^2$ extension of $\\ln(a)$ below eps Parameters: Name Type Description Default a ndarray a Numpy array required deriv bool if True , the first derivative is also returned False eps float a lower bound 1e-30 verbose bool whether diagnoses are printed False Returns: Type Description Union[numpy.ndarray, Tuple[numpy.ndarray, numpy.ndarray]] $\\ln(a)$ $C^2$-extended below eps , with its derivative if deriv is True Source code in cupid_matching/utils.py def nplog ( a : np . ndarray , deriv : bool = False , eps : float = 1e-30 , verbose : bool = False ) -> Union [ np . ndarray , Tuple [ np . ndarray , np . ndarray ]]: \"\"\"$C^2$ extension of $\\ln(a)$ below `eps` Args: a: a Numpy array deriv: if `True`, the first derivative is also returned eps: a lower bound verbose: whether diagnoses are printed Returns: $\\ln(a)$ $C^2$-extended below `eps`, with its derivative if `deriv` is `True` \"\"\" if np . min ( a ) > eps : loga = np . log ( a ) return [ loga , 1.0 / a ] if deriv else loga else : logarreps = np . log ( np . maximum ( a , eps )) logarr_smaller = log ( eps ) - ( eps - a ) * ( 3.0 * eps - a ) / ( 2.0 * eps * eps ) if verbose : n_small_args = np . sum ( a < eps ) if n_small_args > 0 : finals = \"s\" if n_small_args > 1 else \"\" print ( f \"nplog: { n_small_args } argument { finals } smaller than { eps } : mini = { np . min ( a ) } \" ) loga = np . where ( a > eps , logarreps , logarr_smaller ) if deriv : der_logarreps = 1.0 / np . maximum ( a , eps ) der_logarr_smaller = ( 2.0 * eps - a ) / ( eps * eps ) der_loga = np . where ( a > eps , der_logarreps , der_logarr_smaller ) return loga , der_loga else : return loga","title":"nplog()"},{"location":"utils/#cupid_matching.utils.npmaxabs","text":"The maximum absolute value in an array Parameters: Name Type Description Default a ndarray the array required Returns: Type Description float $\\max{ ert a ert}$ Source code in cupid_matching/utils.py def npmaxabs ( a : np . ndarray ) -> float : \"\"\"The maximum absolute value in an array Args: a: the array Returns: $\\max{\\vert a \\vert}$ \"\"\" return np . max ( np . abs ( a ))","title":"npmaxabs()"},{"location":"utils/#cupid_matching.utils.nppow","text":"Evaluates $a^b$ element-by-element Parameters: Name Type Description Default a ndarray a Numpy array required b Union[int, float, numpy.ndarray] if an array, it should have the same shape as a required deriv bool if True , the first derivatives wrt a and b are also returned False Returns: Type Description Union[<built-in function array>, Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]] an array of the same shape as a , and if deriv is True , the derivatives wrt a and b Source code in cupid_matching/utils.py def nppow ( a : np . ndarray , b : Union [ int , float , np . ndarray ], deriv : bool = False ) -> Union [ np . array , Tuple [ np . ndarray , np . ndarray , np . ndarray ]]: \"\"\"Evaluates $a^b$ element-by-element Args: a: a Numpy array b: if an array, it should have the same shape as `a` deriv: if `True`, the first derivatives wrt `a` and `b` are also returned Returns: an array of the same shape as `a`, and if `deriv` is `True`, the derivatives wrt `a` and `b` \"\"\" mina = np . min ( a ) if mina <= 0 : bs_error_abort ( \"All elements of a must be positive!\" ) if isinstance ( b , ( int , float )): a_pow_b = a ** b if deriv : return ( a ** b , b * a_pow_b / a , a_pow_b * log ( a )) else : return a_pow_b else : if a . shape != b . shape : bs_error_abort ( f \"a has shape { a . shape } and b has shape { b . shape } \" ) avec = a . ravel () bvec = b . ravel () a_pow_b = avec ** bvec if deriv : der_wrt_a = a_pow_b * bvec / avec der_wrt_b = a_pow_b * nplog ( avec ) return ( a_pow_b . reshape ( a . shape ), der_wrt_a . reshape ( a . shape ), der_wrt_b . reshape ( a . shape ), ) else : return a_pow_b . reshape ( a . shape )","title":"nppow()"},{"location":"utils/#cupid_matching.utils.nprepeat_col","text":"Creates a matrix with n columns, all equal to v Parameters: Name Type Description Default v ndarray a vector of size m required n int the number of columns requested required :return: a matrix of shape (m, n) Source code in cupid_matching/utils.py def nprepeat_col ( v : np . ndarray , n : int ) -> np . ndarray : \"\"\"Creates a matrix with `n` columns, all equal to `v` Args: v: a vector of size `m` n: the number of columns requested :return: a matrix of shape `(m, n)` \"\"\" _ = test_vector ( v , \"nprepeat_col\" ) return np . repeat ( v [:, np . newaxis ], n , axis = 1 )","title":"nprepeat_col()"},{"location":"utils/#cupid_matching.utils.nprepeat_row","text":"Creates a matrix with m rows, all equal to v Parameters: Name Type Description Default v ndarray a vector of size n required m int the number of rows requested required Returns: Type Description ndarray a matrix of shape (m, n) Source code in cupid_matching/utils.py def nprepeat_row ( v : np . ndarray , m : int ) -> np . ndarray : \"\"\" Creates a matrix with `m` rows, all equal to `v` Args: v: a vector of size `n` m: the number of rows requested Returns: a matrix of shape `(m, n)` \"\"\" _ = test_vector ( v , \"nprepeat_row\" ) return np . repeat ( v [ np . newaxis , :], m , axis = 0 )","title":"nprepeat_row()"},{"location":"utils/#cupid_matching.utils.print_stars","text":"Prints a starred line, or two around the title Parameters: Name Type Description Default title str an optional title None n int the number of stars on the line 70 Returns: Type Description None nothing Source code in cupid_matching/utils.py def print_stars ( title : str = None , n : int = 70 ) -> None : \"\"\"Prints a starred line, or two around the title Args: title: an optional title n: the number of stars on the line Returns: nothing \"\"\" line_stars = \"*\" * n print () print ( line_stars ) if title : print ( title . center ( n )) print ( line_stars ) print ()","title":"print_stars()"},{"location":"utils/#cupid_matching.utils.test_matrix","text":"Tests that x is a matrix; aborts otherwise Parameters: Name Type Description Default x ndarray a potential matrix required fun_name str the name of the calling function None Returns: Type Description Tuple[int, int] the shape of x if it is a matrix Source code in cupid_matching/utils.py def test_matrix ( x : np . ndarray , fun_name : str = None ) -> Tuple [ int , int ]: \"\"\"Tests that `x` is a matrix; aborts otherwise Args: x: a potential matrix fun_name: the name of the calling function Returns: the shape of `x` if it is a matrix \"\"\" fun_str = [ \"\" if fun_name is None else fun_name + \":\" ] if not isinstance ( x , np . ndarray ): bs_error_abort ( f \" { fun_str } x should be a Numpy array\" ) ndims_x = x . ndim if ndims_x != 2 : bs_error_abort ( f \" { fun_str } x should have two dimensions, not { ndims_x } \" ) return x . shape","title":"test_matrix()"},{"location":"utils/#cupid_matching.utils.test_vector","text":"Tests that x is a vector; aborts otherwise Parameters: Name Type Description Default x ndarray a potential vector required fun_name str the name of the calling function None Returns: Type Description int the size of x if it is a vector Source code in cupid_matching/utils.py def test_vector ( x : np . ndarray , fun_name : str = None ) -> int : \"\"\"Tests that `x` is a vector; aborts otherwise Args: x: a potential vector fun_name: the name of the calling function Returns: the size of `x` if it is a vector \"\"\" fun_str = [ \"\" if fun_name is None else fun_name + \":\" ] if not isinstance ( x , np . ndarray ): bs_error_abort ( f \" { fun_str } x should be a Numpy array\" ) ndims_x = x . ndim if ndims_x != 1 : bs_error_abort ( f \" { fun_str } x should have one dimension, not { ndims_x } \" ) return x . size","title":"test_vector()"}]}